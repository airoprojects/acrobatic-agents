{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Packages installation\n",
        "!pip install -q gymnasium\n",
        "!pip install -q stable_baselines3\n",
        "!pip install -q gymnasium[mujoco]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "zeGbFEQHRc95",
        "outputId": "0ffa8ec7-4b43-4617-9805-e150da06f601"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset**\n",
        "\n",
        "This section is dedicated to collect data taking advantage of an expert policy provided by stable baseline. In this case the policy strategy used is PPO."
      ],
      "metadata": {
        "id": "Bdq0oWPsUlMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Hmx6eDERTFev"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9zqWPqCRTG-",
        "outputId": "97adcb7d-93eb-4ddb-8c03-e0dd62c2e434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'Humanoid-v4'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 22.5     |\n",
            "|    ep_rew_mean     | 110      |\n",
            "| time/              |          |\n",
            "|    fps             | 610      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.1        |\n",
            "|    ep_rew_mean          | 108         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020223018 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24.1       |\n",
            "|    explained_variance   | 0.00799     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 484         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0622     |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 1.56e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.3        |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026106814 |\n",
            "|    clip_fraction        | 0.286       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24         |\n",
            "|    explained_variance   | 0.0162      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 384         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0764     |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 1.17e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.8        |\n",
            "|    ep_rew_mean          | 111         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 408         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027711213 |\n",
            "|    clip_fraction        | 0.305       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24.1       |\n",
            "|    explained_variance   | 0.023       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 441         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0801     |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 1.09e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 24.3        |\n",
            "|    ep_rew_mean          | 119         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 400         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.032687034 |\n",
            "|    clip_fraction        | 0.364       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -24         |\n",
            "|    explained_variance   | 0.0136      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 335         |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.089      |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 982         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.8        |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 403         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038142994 |\n",
            "|    clip_fraction        | 0.385       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | 0.0128      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 498         |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0896     |\n",
            "|    std                  | 0.988       |\n",
            "|    value_loss           | 1.03e+03    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 25.3       |\n",
            "|    ep_rew_mean          | 123        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 392        |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 36         |\n",
            "|    total_timesteps      | 14336      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04435309 |\n",
            "|    clip_fraction        | 0.429      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -23.9      |\n",
            "|    explained_variance   | 0.0156     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 432        |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0924    |\n",
            "|    std                  | 0.988      |\n",
            "|    value_loss           | 849        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.1        |\n",
            "|    ep_rew_mean          | 127         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 396         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.037674434 |\n",
            "|    clip_fraction        | 0.384       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | 0.0215      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 580         |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0891     |\n",
            "|    std                  | 0.985       |\n",
            "|    value_loss           | 1.07e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.6        |\n",
            "|    ep_rew_mean          | 141         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 398         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 46          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028040685 |\n",
            "|    clip_fraction        | 0.291       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | 0.0288      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 410         |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0798     |\n",
            "|    std                  | 0.986       |\n",
            "|    value_loss           | 1.04e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.2        |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028665628 |\n",
            "|    clip_fraction        | 0.287       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | 0.0318      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 655         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0787     |\n",
            "|    std                  | 0.985       |\n",
            "|    value_loss           | 1.24e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.9        |\n",
            "|    ep_rew_mean          | 143         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 394         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023814566 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.9       |\n",
            "|    explained_variance   | 0.0867      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 552         |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0727     |\n",
            "|    std                  | 0.984       |\n",
            "|    value_loss           | 1.14e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.7        |\n",
            "|    ep_rew_mean          | 142         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 389         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020476963 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 448         |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0676     |\n",
            "|    std                  | 0.981       |\n",
            "|    value_loss           | 1.22e+03    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 28.3        |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 391         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019395407 |\n",
            "|    clip_fraction        | 0.197       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 371         |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0666     |\n",
            "|    std                  | 0.98        |\n",
            "|    value_loss           | 904         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 30.2        |\n",
            "|    ep_rew_mean          | 149         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 393         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017495597 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | 0.299       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 367         |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0619     |\n",
            "|    std                  | 0.98        |\n",
            "|    value_loss           | 829         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 32.3        |\n",
            "|    ep_rew_mean          | 159         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 389         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019181184 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -23.8       |\n",
            "|    explained_variance   | 0.341       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 591         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0617     |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 1.1e+03     |\n",
            "-----------------------------------------\n",
            "Mean reward expert agent= 431.10106970000004 +/- 48.2536664106748\n"
          ]
        }
      ],
      "source": [
        "#@title Create the environment\n",
        "\n",
        "env_id = \"Humanoid-v4\"\n",
        "env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "\n",
        "# Instantiate the agent\n",
        "expert_model = PPO(\"MlpPolicy\", env_id, verbose=1)\n",
        "\n",
        "# Train the agent\n",
        "expert_model.learn(total_timesteps=3e4)\n",
        "\n",
        "#evaluate expert\n",
        "mean_reward, std_reward = evaluate_policy(expert_model, Monitor(env), n_eval_episodes=10)\n",
        "print(f\"Mean reward expert agent= {mean_reward} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title create expert dataset\n",
        "\n",
        "#empty dataset\n",
        "num_interactions = int(4e4)\n",
        "\n",
        "expert_observations = np.empty((num_interactions,) + env.observation_space.shape)\n",
        "expert_actions = np.empty((num_interactions,) + env.action_space.shape)\n",
        "\n",
        "print(expert_observations.shape)\n",
        "print(expert_actions.shape)\n",
        "\n",
        "#collect experience usign expert policy\n",
        "obs, _ = env.reset()\n",
        "for i in tqdm(range(num_interactions)):\n",
        "    action, _ = expert_model.predict(obs, deterministic=True)\n",
        "    expert_observations[i] = obs\n",
        "    expert_actions[i] = action\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    if done:\n",
        "        obs, _ = env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0RoJK6hTUOU",
        "outputId": "5a2eac88-4e88-4b90-b14f-5b922bea625f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 376)\n",
            "(40000, 17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [01:14<00:00, 533.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title save dataset\n",
        "np.savez_compressed(\n",
        "   \"expert-data\",\n",
        "   expert_actions=expert_actions,\n",
        "   expert_observations=expert_observations,\n",
        "   )"
      ],
      "metadata": {
        "id": "sKrrhmvxTlE-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title dataset class\n",
        "from torch.utils.data.dataset import Dataset, random_split\n",
        "\n",
        "class ExpertDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = expert_observations\n",
        "        self.actions = expert_actions\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.observations[index], self.actions[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)"
      ],
      "metadata": {
        "id": "3KvPRQ3pTswF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "expert_dataset = ExpertDataSet(expert_observations, expert_actions)\n",
        "\n",
        "#split in 80% training and 20%test\n",
        "batch_size = 64\n",
        "train_prop = 0.8\n",
        "train_size = int(train_prop * len(expert_dataset))\n",
        "test_size = len(expert_dataset) - train_size\n",
        "train_expert_dataset, test_expert_dataset = random_split(expert_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(  dataset=train_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(  dataset=test_expert_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFeSoOjXUhzA",
        "outputId": "462ffc1d-fb72-4f82-b250-96afef4176f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}