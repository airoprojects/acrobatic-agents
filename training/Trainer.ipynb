{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5746635",
      "metadata": {},
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b09a0b12",
      "metadata": {
        "id": "b09a0b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cpu\n",
            "root: /home/leeoos/Projects/master/airo-rl/acrobatic-agents\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import joblib\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "from git import Repo\n",
        "from os.path import exists\n",
        "from os import mkdir, remove, rename\n",
        "# from .autonotebook import tqdm as notebook_tqdm\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.dataset import Dataset, random_split\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# set up train device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device: {}\".format(device))\n",
        "\n",
        "# setup project root dir\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "if COLAB:\n",
        "  root_dir = '/content'\n",
        "  %mkdir ./data/\n",
        "else:\n",
        "  repo = Repo(\".\", search_parent_directories=True)\n",
        "  root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
        "  sys.path.insert(0, root_dir+'/models/')\n",
        "print(\"root: {}\".format(root_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf0c1cf5",
      "metadata": {},
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "0558881a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task type: mixed\n",
            "Observations: (25000, 197)\n",
            "Actions: (25000, 36)\n"
          ]
        }
      ],
      "source": [
        "# Classic: Import data and build dataloader\n",
        "experimental = True\n",
        "\n",
        "availables_tasks = {\n",
        "    0: 'backflip', \n",
        "    1: 'spinkick', \n",
        "    2: 'jump'\n",
        "}\n",
        "\n",
        "if not experimental: \n",
        "\n",
        "    task_type = availables_tasks[0] #insert here\n",
        "    dataset_len = 5000\n",
        "    tag=''\n",
        "    import_dir = root_dir+'/data/'+ task_type + '/'\n",
        "    raw_expert_observations = np.load(import_dir+'/expert-observations-'+str(dataset_len)+'.npy', allow_pickle=True)\n",
        "    expert_actions = np.load(import_dir+'expert-actions-'+str(dataset_len)+'.npy', allow_pickle=True)\n",
        "\n",
        "else:\n",
        "\n",
        "    #Experimental: Run this cell to train on both tasks\n",
        "    task_type = 'mixed'\n",
        "\n",
        "    # Import for task 1\n",
        "    dataset_len_1 = 20000\n",
        "    task_1 = 'backflip'\n",
        "    import_dir_1 = root_dir+'/data/'+ task_1 + '/'\n",
        "    raw_expert_observations_bf = np.load(import_dir_1+'/expert-observations-'+str(dataset_len_1)+'.npy', allow_pickle=True)\n",
        "    expert_actions_bf = np.load(import_dir_1+'expert-actions-'+str(dataset_len_1)+'.npy', allow_pickle=True)\n",
        "\n",
        "    # import for task 2\n",
        "    dataset_len_2 = 20000\n",
        "    task_2 = 'spinkick'\n",
        "    import_dir_2 = root_dir+'/data/'+ task_2 + '/'\n",
        "    raw_expert_observations_sk = np.load(import_dir_2+'/expert-observations-'+str(dataset_len_2)+'.npy', allow_pickle=True)\n",
        "    expert_actions_sk = np.load(import_dir_2+'expert-actions-'+str(dataset_len_2)+'.npy', allow_pickle=True)\n",
        "\n",
        "    # import for task 3\n",
        "    dataset_len_3 = 20000\n",
        "    task_3 = 'jump'\n",
        "    import_dir_3 = root_dir+'/data/'+ task_3 + '/'\n",
        "    raw_expert_observations_jp = np.load(import_dir_3+'/expert-observations-'+str(dataset_len_3)+'.npy', allow_pickle=True)\n",
        "    expert_actions_jp = np.load(import_dir_3+'expert-actions-'+str(dataset_len_3)+'.npy', allow_pickle=True)\n",
        "\n",
        "    # decide task wheigt by trimming the datasets\n",
        "    raw_expert_observations_bf = raw_expert_observations_bf[:5000]\n",
        "    expert_actions_bf = expert_actions_bf[:5000]\n",
        "\n",
        "    raw_expert_observations_sk = raw_expert_observations_sk[:]\n",
        "    expert_actions_sk = expert_actions_sk[:]\n",
        "\n",
        "    raw_expert_observations_jp = raw_expert_observations_jp[:0]\n",
        "    expert_actions_jp = expert_actions_jp[:0]\n",
        "\n",
        "    w1 = int(np.ceil(len(raw_expert_observations_bf) / (len(raw_expert_observations_bf) + 1)))\n",
        "    w2 = int(np.ceil(len(raw_expert_observations_sk) / (len(raw_expert_observations_sk) + 1)))\n",
        "    w3 = int(np.ceil(len(raw_expert_observations_jp) / (len(raw_expert_observations_jp) + 1)))\n",
        "    tag = task_1[0]*w1 + task_2[4]*w2 + task_3[0]*w3\n",
        "\n",
        "    dataset_len = len(raw_expert_observations_bf) + len(raw_expert_observations_sk) + len(raw_expert_observations_jp)\n",
        "\n",
        "    # concatenate tasks\n",
        "    raw_expert_observations = np.concatenate([raw_expert_observations_bf, raw_expert_observations_sk, raw_expert_observations_jp],axis=0)\n",
        "    expert_actions = np.concatenate([expert_actions_bf, expert_actions_sk, expert_actions_jp],axis=0)\n",
        "\n",
        "print('Task type: {}'.format(task_type))\n",
        "print('Observations: {}'.format(raw_expert_observations.shape))\n",
        "print('Actions: {}'.format(expert_actions.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa60adfe",
      "metadata": {},
      "source": [
        "# Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "dbe93baa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/home/leeoos/Projects/master/airo-rl/acrobatic-agents/data/mixed/scaler-25000-bk.joblib']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Robust scaling\n",
        "\n",
        "# Create a robust scaler object\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit the scaler to your data\n",
        "scaler.fit(raw_expert_observations)\n",
        "expert_observations = scaler.transform(raw_expert_observations)\n",
        "\n",
        "# This will save the scaler to a file named 'scaler-xxxx.joblib'\n",
        "save_dir = root_dir+'/data/'+str(task_type)+'/'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "joblib.dump(scaler, save_dir+'scaler-'+str(dataset_len)+'-'+str(tag)+'.joblib')  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3820d87",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ce03945f",
      "metadata": {
        "id": "ce03945f"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "\n",
        "class ExpertDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = torch.from_numpy(expert_observations).float()\n",
        "        self.actions = self.__preprocess__(torch.from_numpy(expert_actions))\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.observations[index], self.actions[index])\n",
        "        # normalized_observations = 2 * ((self.observations[idx] - self.observations.min()) / (self.observations.max() - self.observations.min())) - 1\n",
        "        # normalized_data = (normalized_observations, self.actions[idx])\n",
        "        # return normalized_data\n",
        "        return self.observations[idx], self.actions[idx]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "    \n",
        "    \n",
        "    def __preprocess__(self, data, clip_value=1e38):\n",
        "        # Clip values to a maximum and minimum range\n",
        "        data = torch.clamp(data, min=-clip_value, max=clip_value)\n",
        "        \n",
        "        # Convert to float\n",
        "        return data.float()\n",
        "    \n",
        "    def __min__max__(self):\n",
        "        return self.observations.min(), self.observations.max() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "11af5407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11af5407",
        "outputId": "bc497a92-1701-4426-c1cd-4fb74f7545cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert actions len: 25000\n",
            "Expert observations len: 25000\n",
            "Discarded form np: 0\n",
            "Discarded form torch: 0\n",
            "Observations min: -21.900846481323242\n",
            "Observations max: 19.29659652709961\n"
          ]
        }
      ],
      "source": [
        "# Make Datasets \n",
        "\n",
        "count_discarded_numpy = 0\n",
        "count_discarded = 0\n",
        "\n",
        "list_of_index_to_drop = []\n",
        "for i, a in enumerate(expert_actions):\n",
        "  if (a > 1e2).any() or (a > 1e2).any():\n",
        "  # if not np.isfinite(a).all(): \n",
        "    list_of_index_to_drop.append(i)\n",
        "    # print(i)\n",
        "    # print(a)\n",
        "    count_discarded_numpy+=1\n",
        "    # break\n",
        "\n",
        "\n",
        "print(\"Expert actions len: {}\".format(len(expert_actions)))\n",
        "print(\"Expert observations len: {}\".format(len(expert_observations)))\n",
        "\n",
        "expert_dataset = ExpertDataSet(expert_observations, expert_actions)\n",
        "\n",
        "for i in range(len(expert_dataset)):\n",
        "  a = expert_dataset.__getitem__(i)[1]\n",
        "  # print(a.max())\n",
        "  # print(a.min())\n",
        "  if (a > 1e2).any() or (a < -1e2).any() :\n",
        "  # if not torch.isfinite(a).any():\n",
        "    count_discarded += 1\n",
        "    # print(a)\n",
        "\n",
        "print(\"Discarded form np: {}\".format(count_discarded_numpy))\n",
        "print(\"Discarded form torch: {}\".format(count_discarded))\n",
        "\n",
        "min_val, max_val = expert_dataset.__min__max__()\n",
        "\n",
        "print(\"Observations min: {}\".format(min_val))\n",
        "print(\"Observations max: {}\".format(max_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "56a9ee4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions shape: torch.Size([36])\n",
            "Observations shape: torch.Size([197])\n"
          ]
        }
      ],
      "source": [
        "# Data Loaders\n",
        "\n",
        "batch_size = 128\n",
        "train_prop = 0.7\n",
        "train_size = int(train_prop * len(expert_dataset))\n",
        "test_size = int(0.2 * len(expert_dataset))\n",
        "val_size = int(0.1 * len(expert_dataset))\n",
        "train_expert_dataset, test_expert_dataset,val_expert_dataset = random_split(expert_dataset, [train_size, test_size,val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_expert_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader( dataset=val_expert_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Actions shape: {}\".format(train_loader.dataset.__getitem__(0)[1].shape))\n",
        "print(\"Observations shape: {}\".format(train_loader.dataset.__getitem__(0)[0].shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0fbfbb2",
      "metadata": {},
      "source": [
        "# BCO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae4e82b",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "94873ce1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy net: BCOAgentFC(\n",
            "  (fc1): Linear(in_features=197, out_features=394, bias=True)\n",
            "  (bn1): BatchNorm1d(394, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=394, out_features=36, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Policy Agent FC\n",
        "import bco_fc as bco\n",
        "\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = bco.BCOAgentFC(obs_space, action_space, h_size=obs_space*2).to(device)\n",
        "\n",
        "print(\"Policy net: {}\".format(policy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8afe7403",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy net: BCOCNN(\n",
            "  (conv1): Conv1d(1, 36, kernel_size=(5,), stride=(2,), padding=(1,))\n",
            "  (conv2): Conv1d(36, 36, kernel_size=(3,), stride=(2,), padding=(2,))\n",
            "  (fc1): Linear(in_features=1800, out_features=72, bias=True)\n",
            "  (LRelu): LeakyReLU(negative_slope=0.01)\n",
            "  (fc2): Linear(in_features=72, out_features=36, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Policy Agent CNN\n",
        "\n",
        "import bco_cnn as bco_cnn\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = bco_cnn.BCOCNN(obs_space, action_space).to(device) # fix add hidden layer size\n",
        "\n",
        "print(\"Policy net: {}\".format(policy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fd7301",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "09e78876",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training env:\n",
            "BCOAgentFC(\n",
            "  (fc1): Linear(in_features=197, out_features=394, bias=True)\n",
            "  (bn1): BatchNorm1d(394, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=394, out_features=36, bias=True)\n",
            ")\n",
            "Loss function: MSELoss()\n",
            "Optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    initial_lr: 0.001\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Batch size: 128\n"
          ]
        }
      ],
      "source": [
        "# Train functions\n",
        "\n",
        "def train(\n",
        "        policy,\n",
        "        train_epochs,\n",
        "        train_loader, \n",
        "        val_loader,\n",
        "        optimizer,\n",
        "        loss_criterion,\n",
        "        scheduler,\n",
        "        thrashold\n",
        "    ):\n",
        "\n",
        "    policy.train()\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    unused_val = 0\n",
        "\n",
        "    with tqdm(total=train_epochs, leave=True) as pbar:\n",
        "        losses = np.empty(train_epochs)\n",
        "        v_losses = np.empty(train_epochs)\n",
        "        for epoch in range(train_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "\n",
        "                if policy.name == 'bco-cnn':\n",
        "                    obs = obs.unsqueeze(1)\n",
        "                \n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                student_action = policy(obs)\n",
        "                expert_action = expert_action.float()\n",
        "\n",
        "                loss = loss_criterion(student_action, expert_action)\n",
        "                # loss.register_hook(lambda grad: print(grad))\n",
        "                loss.backward()\n",
        "                # print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "                if not loss.item() == torch.inf: \n",
        "                    epoch_loss += loss.item()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "\n",
        "                else:\n",
        "                    unused_val += 1\n",
        "                    print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                    print(f'obs -> {obs}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'expert_action -> {expert_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'student_action -> {student_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    return expert_action,student_action\n",
        "\n",
        "                res = print_gradients(policy)\n",
        "                \n",
        "                if torch.isnan(student_action).any(): \n",
        "                    print('e successo')\n",
        "                    break\n",
        "\n",
        "                if res == 1: \n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(student_action.shape)\n",
        "                    for i, ea in enumerate(expert_action):\n",
        "                        if not np.isfinite(ea).all():\n",
        "                            print(i+64)\n",
        "                            print(f'expert_action -> {ea}')\n",
        "\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'Max expert_action -> {expert_action.max()}')\n",
        "                    print(f'Min expert_action -> {expert_action.min()}')\n",
        "                    print(f'Max student_action -> {student_action.max()}')\n",
        "                    print(f'Min student_action -> {student_action.min()}')\n",
        "                    break\n",
        "            \n",
        "            t_loss = epoch_loss/(batch_idx+1)\n",
        "            v_loss = validation(val_loader, policy, loss_criterion)\n",
        "            epoch_loss = 0\n",
        "            unused_val = 0\n",
        "            v_losses[epoch]=v_loss\n",
        "            losses[epoch]=t_loss\n",
        "            pbar.set_postfix(train=t_loss, validation=v_loss)\n",
        "            pbar.update(1)\n",
        "            \n",
        "        \n",
        "        print(\"###############################################################################\\n\")\n",
        "        print(\"Train Loss: {}\".format(t_loss))\n",
        "        print(\"Validation Loss: {}\".format(v_loss))\n",
        "        print(\"###############################################################################\\n\")\n",
        "\n",
        "    np.save('t_losses.npy', np.array(losses, dtype=object), allow_pickle=True)\n",
        "    np.save('v_losses.npy', np.array(v_losses, dtype=object), allow_pickle=True)\n",
        "\n",
        "def validation(loader, policy,loss_criterion):\n",
        "    policy.eval()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        obs, expert_action = data.to(device), target.to(device)\n",
        "        obs = obs.float()\n",
        "        if policy.name == 'bco-cnn':\n",
        "            obs = obs.unsqueeze(1)\n",
        "        student_action = policy(obs)\n",
        "        loss = loss_criterion(student_action, expert_action)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/(batch_idx+1)\n",
        "\n",
        "def print_gradients(policy):\n",
        "    for name, param in policy.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if torch.isnan(param.grad).any(): \n",
        "                return 1#break\n",
        "            # print(f\"Gradient of {name}: {param.grad}\")\n",
        "    return 0\n",
        "\n",
        "# Train module\n",
        "\n",
        "loss_criterion = nn.MSELoss()\n",
        "# Create a learning rate scheduler\n",
        "step_size = 80\n",
        "gamma = 0.3\n",
        "learning_rate = 1e-3\n",
        "optimizer =  optim.Adam(policy.parameters(), lr=learning_rate)\n",
        "optimizer =  optim.SGD(policy.parameters(), lr=learning_rate, momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "eval_epochs = 5\n",
        "\n",
        "print(\"Training env:\")\n",
        "print(policy)\n",
        "print(\"Loss function: {}\".format(loss_criterion))\n",
        "print(\"Optimizer: {}\".format(optimizer))\n",
        "print(\"Batch size: {}\".format(batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "b1944c35",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [06:24<00:00,  5.20it/s, train=0.00096, validation=0.00124] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###############################################################################\n",
            "\n",
            "Train Loss: 0.0009603833615691503\n",
            "Validation Loss: 0.0012369466247037053\n",
            "###############################################################################\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(policy, \n",
        "      train_epochs=2000, \n",
        "      train_loader=train_loader, \n",
        "      val_loader=val_loader,\n",
        "      optimizer=optimizer,\n",
        "      loss_criterion=loss_criterion,\n",
        "      scheduler=scheduler,\n",
        "      thrashold = 100\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dba6867",
      "metadata": {},
      "source": [
        "## Load losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "742a9a6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.3490727497060804 0.25288042154190316 0.24048466806429147 ...\n",
            " 0.18900136203661452 0.1889384159424009 0.18888150470970322]\n"
          ]
        }
      ],
      "source": [
        "#Load losses\n",
        "ta = np.load('t_losses.npy',allow_pickle=True)\n",
        "tva = np.load('v_losses.npy',allow_pickle=True)\n",
        "\n",
        "print(ta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f15e40",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "e6143335",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(policy, test_loader,loss_criterion):\n",
        "    policy.eval()   \n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "\n",
        "        obs, expert_action = data.to(device), target.to(device)\n",
        "        obs = obs.float()\n",
        "        \n",
        "        if policy.name == 'bco-cnn':\n",
        "            obs = obs.unsqueeze(1)\n",
        "\n",
        "        student_action = policy(obs)\n",
        "        expert_action = expert_action.float()\n",
        "\n",
        "        loss = loss_criterion(student_action, expert_action)\n",
        "\n",
        "        if not loss.item() == torch.inf: \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        if torch.isnan(student_action).any(): \n",
        "            print('e successo')\n",
        "            break\n",
        "        \n",
        "    t_loss = epoch_loss/(batch_idx+1)\n",
        "    epoch_loss = 0\n",
        "            \n",
        "    \n",
        "    print(\"Test Loss: {}\".format(t_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "99284dae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.001251277966366615\n"
          ]
        }
      ],
      "source": [
        "test(policy=policy, test_loader=test_loader, loss_criterion=loss_criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75da1acc",
      "metadata": {},
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "82745485",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lookup table updated\n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "\n",
        " # saving\n",
        "save_dir = root_dir+'/checkpoints/'+str(task_type)+'/'\n",
        "if not os.path.exists(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "\n",
        "version = str(dataset_len)[:-3] + 'k-' + str(tag)\n",
        "policy.save_parameters(save_dir, version)\n",
        "\n",
        "# Path to the JSON file\n",
        "file_path = root_dir + '/versions/model_versions.json'\n",
        "\n",
        "model_type = policy.name + '-' + task_type\n",
        "model_version = version\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "\n",
        "    # Read the existing data\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    # Update the data\n",
        "    if model_type in data:\n",
        "        if model_version not in data[model_type]:\n",
        "            data[model_type].append(model_version)\n",
        "    else:\n",
        "        data[model_type] = [model_version]\n",
        "\n",
        "else:\n",
        "    # File doesn't exist, use update_data as the initial data\n",
        "    data = {\n",
        "        model_type: [model_version]\n",
        "    }\n",
        "\n",
        "# Write the updated data back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    json.dump(data, file, indent=4)\n",
        "\n",
        "print(\"Lookup table updated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc5191c",
      "metadata": {},
      "source": [
        "## Loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "57b3ac73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model Behavioral-Cloning-Agent state parameters\n",
            "From :/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/checkpoints/behavioral-cloning-agent.pt\n",
            "/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/checkpoints/behavioral-cloning-agent.pt\n"
          ]
        }
      ],
      "source": [
        "src = root_dir+'/checkpoints/'+policy.name.lower()+'.pt'\n",
        "policy.load_parameters(src)\n",
        "print(root_dir+'/checkpoints/'+policy.name.lower()+'.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
