{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5746635",
      "metadata": {},
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b09a0b12",
      "metadata": {
        "id": "b09a0b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: cuda\n",
            "root: /home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/.venv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import joblib\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from os import path\n",
        "from git import Repo\n",
        "from os.path import exists\n",
        "from os import mkdir, remove, rename\n",
        "# from .autonotebook import tqdm as notebook_tqdm\n",
        "\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.dataset import Dataset, random_split\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# set up train device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device: {}\".format(device))\n",
        "\n",
        "# setup project root dir\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "if COLAB:\n",
        "  root_dir = '/content'\n",
        "  %mkdir ./data/\n",
        "else:\n",
        "  repo = Repo(\".\", search_parent_directories=True)\n",
        "  root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
        "  sys.path.insert(0, root_dir+'/models/')\n",
        "print(\"root: {}\".format(root_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0558881a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import data and build dataloader\n",
        "dataset_len = 6000\n",
        "raw_expert_observations = np.load(root_dir+'/data/expert-observations-'+str(dataset_len)+'.npy', allow_pickle=True)\n",
        "expert_actions = np.load(root_dir+'/data/expert-actions-'+str(dataset_len)+'.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dbe93baa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/data/scaler-6000.joblib']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Robust scaling\n",
        "\n",
        "# Create a robust scaler object\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Fit the scaler to your data\n",
        "scaler.fit(raw_expert_observations)\n",
        "expert_observations = scaler.transform(raw_expert_observations)\n",
        "\n",
        "# This will save the scaler to a file named 'scaler.joblib'\n",
        "joblib.dump(scaler, root_dir+'/data/scaler-'+str(dataset_len)+'.joblib')  \n",
        "\n",
        "# with open(root_dir+'/data/scaler-'+str(dataset_len)+'.joblib', 'wb') as file:\n",
        "#     pickle.dump(scaler, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0fbfbb2",
      "metadata": {},
      "source": [
        "# BCO FC1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3820d87",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce03945f",
      "metadata": {
        "id": "ce03945f"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "\n",
        "class ExpertDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = torch.from_numpy(expert_observations).float()\n",
        "        self.actions = self.__preprocess__(torch.from_numpy(expert_actions))\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.observations[index], self.actions[index])\n",
        "        # normalized_observations = 2 * ((self.observations[idx] - self.observations.min()) / (self.observations.max() - self.observations.min())) - 1\n",
        "        # normalized_actions = 2 * ((self.actions[idx] - self.actions.min()) / (self.actions.max() - self.actions.min())) - 1\n",
        "        # normalized_data = (normalized_observations, self.actions[idx])\n",
        "        # return normalized_data\n",
        "        return self.observations[idx], self.actions[idx]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "    \n",
        "    \n",
        "    def __preprocess__(self, data, clip_value=1e38):\n",
        "        # Clip values to a maximum and minimum range\n",
        "        data = torch.clamp(data, min=-clip_value, max=clip_value)\n",
        "        \n",
        "        # Convert to float\n",
        "        return data.float()\n",
        "    \n",
        "    def __min__max__(self):\n",
        "        return self.observations.min(), self.observations.max() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "11af5407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11af5407",
        "outputId": "bc497a92-1701-4426-c1cd-4fb74f7545cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert actions len: 6000\n",
            "Expert observations len: 6000\n",
            "Discarded data:\n",
            "Discarded form np: 0\n",
            "Discarded form torch: 0\n",
            "Statistics: \n",
            "Observations min: -43.44462203979492\n",
            "Observations max: 25.609783172607422\n"
          ]
        }
      ],
      "source": [
        "# Make Datasets \n",
        "\n",
        "count_discarded_numpy = 0\n",
        "count_discarded = 0\n",
        "\n",
        "new_exp_action = expert_actions\n",
        "\n",
        "list_of_index_to_drop = []\n",
        "for i, a in enumerate(expert_actions):\n",
        "  if (a > 1e2).any() or (a > 1e2).any():\n",
        "  # if not np.isfinite(a).all(): \n",
        "    list_of_index_to_drop.append(i)\n",
        "    # print(i)\n",
        "    # print(a)\n",
        "    count_discarded_numpy+=1\n",
        "    # break\n",
        "\n",
        "\n",
        "print(\"Expert actions len: {}\".format(len(expert_actions)))\n",
        "print(\"Expert observations len: {}\".format(len(expert_observations)))\n",
        "\n",
        "expert_dataset = ExpertDataSet(expert_observations, expert_actions)\n",
        "\n",
        "for i in range(len(expert_dataset)):\n",
        "  a = expert_dataset.__getitem__(i)[1]\n",
        "  # print(a.max())\n",
        "  # print(a.min())\n",
        "  if (a > 1e2).any() or (a < -1e2).any() :\n",
        "  # if not torch.isfinite(a).any():\n",
        "    count_discarded += 1\n",
        "    # print(a)\n",
        "\n",
        "print(\"Discarded data:\")\n",
        "print(\"Discarded form np: {}\".format(count_discarded_numpy))\n",
        "print(\"Discarded form torch: {}\".format(count_discarded))\n",
        "\n",
        "min_val, max_val = expert_dataset.__min__max__()\n",
        "\n",
        "print(\"Statistics: \")\n",
        "print(\"Observations min: {}\".format(min_val))\n",
        "print(\"Observations max: {}\".format(max_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9af119be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 7.15714286e-01  7.30014086e-01  2.83791423e-02  9.70363617e-03\n",
            "  6.32491708e-02  6.87499523e-01  4.34871405e-01 -3.10895652e-01\n",
            " -4.91503000e-01  1.44381285e-01  5.32424450e-02  3.21142405e-01\n",
            "  6.91232085e-01  4.16582197e-01 -3.28087777e-01 -4.90933746e-01\n",
            "  2.79643804e-01  7.12199211e-02  5.62593341e-01  6.54284537e-01\n",
            "  4.10000980e-01 -2.69350946e-01 -5.75552821e-01 -4.09491658e-02\n",
            " -1.86350763e-01  1.66778445e-01  8.14477742e-01 -2.45841160e-01\n",
            " -4.70354915e-01  2.34423488e-01 -8.50124955e-02 -5.13072416e-01\n",
            "  2.12468147e-01  7.96494067e-01  7.79825747e-02 -5.24966955e-01\n",
            " -2.89699256e-01 -1.44465506e-01 -7.05847956e-01  1.63728476e-01\n",
            "  8.51464689e-01 -2.05010585e-02 -5.23900747e-01  1.07551673e-02\n",
            " -1.79333091e-02 -6.94095492e-02  4.56959963e-01  9.39763069e-01\n",
            "  1.56709135e-01 -2.14659110e-01 -2.14963004e-01 -5.86979389e-02\n",
            " -3.02378953e-01  3.79739106e-01  9.64010119e-01  1.06653832e-01\n",
            " -2.43436322e-01 -6.94104703e-03 -5.33422828e-02 -4.38151509e-01\n",
            "  3.50697815e-01  9.64010119e-01  1.06653832e-01 -2.43436322e-01\n",
            " -6.94104703e-03  1.23626649e-01 -1.41121447e-01  8.17760825e-02\n",
            "  7.49997139e-01 -1.57388225e-01 -5.76708019e-01  2.83092022e-01\n",
            "  1.69632912e-01 -4.92921099e-01  1.24123037e-01  7.91599095e-01\n",
            "  1.49630740e-01 -5.78769326e-01 -1.26521587e-01  1.70966387e-01\n",
            " -7.06479078e-01  8.93830061e-02  7.70023763e-01 -4.99205329e-02\n",
            " -6.36046827e-01 -3.97216529e-03  3.82298052e-01  2.79549956e-02\n",
            "  2.81435907e-01  5.69784403e-01  2.66194046e-01 -7.67308950e-01\n",
            " -1.25393465e-01  4.39083934e-01 -1.99670494e-01  1.93110347e-01\n",
            "  5.83031476e-01  1.24387652e-01 -8.02589595e-01 -2.12615058e-02\n",
            "  4.63381916e-01 -3.34192216e-01  1.68214917e-01  5.83031476e-01\n",
            "  1.24387652e-01 -8.02589595e-01 -2.12615058e-02 -7.64119148e-01\n",
            " -1.30883038e+00 -1.40973747e+00 -8.44599545e-01 -1.30396056e+00\n",
            "  3.08658093e-01 -1.10245502e+00 -1.02782619e+00 -1.30559766e+00\n",
            " -1.44626164e+00 -1.34483898e+00 -4.61378545e-01 -1.49148488e+00\n",
            " -9.72319663e-01 -1.10368776e+00 -5.01737058e-01 -1.83644402e+00\n",
            " -1.44213605e+00 -3.35594654e-01 -6.46401584e-01 -7.17798352e-01\n",
            " -5.02210140e+00  5.31894147e-01  1.94049561e+00  1.19936857e-02\n",
            "  9.84447002e-02  7.16285110e-02 -1.48235828e-01 -4.63061124e-01\n",
            " -4.73944962e-01 -2.63042729e-02  5.60006537e-02  2.58428622e-02\n",
            "  1.71268094e+00 -5.05966619e-02  1.79562032e-01 -1.04252458e+00\n",
            " -8.76572430e-01 -1.34049201e+00 -2.61742520e+00 -4.20305777e+00\n",
            "  7.39960730e-01 -4.87920195e-01 -1.11312819e+00 -8.71443927e-01\n",
            " -2.87407422e+00 -4.31330490e+00  1.20805192e+00 -1.98635757e-01\n",
            " -1.19012535e+00 -4.58123028e-01 -2.87407422e+00 -4.31330490e+00\n",
            "  1.20805192e+00 -2.50713170e-01 -6.61737084e-01 -5.24746120e-01\n",
            " -5.26116133e+00  6.44366562e-01  1.88047290e+00  6.06706813e-02\n",
            "  1.20610021e-01  1.83967263e-01  7.80943513e-01  1.21707094e+00\n",
            "  7.40297139e-02 -3.33958901e-02  1.24989718e-01  1.60519164e-02\n",
            "  1.19396448e+00 -1.67626478e-02 -4.91108239e-01 -7.70990610e-01\n",
            " -1.53738320e+00 -2.22867802e-01 -7.56988049e+00 -1.81134045e+00\n",
            "  1.76184475e+00 -1.38171703e-01 -2.05023098e+00  1.37208652e+00\n",
            " -5.62297773e+00 -1.58189857e+00  2.42224097e+00  2.27054417e-01\n",
            " -2.13136220e+00  2.16693616e+00 -5.62297773e+00 -1.58189857e+00\n",
            "  2.42224097e+00]\n",
            "tensor([ 4.3872e-01, -6.6150e-01,  3.8245e-01, -8.9508e-01,  6.0001e+00,\n",
            "        -9.4895e-01,  3.5635e+00, -3.8216e+00, -1.8629e+00,  2.8845e-01,\n",
            "        -8.5640e-01,  6.2733e+00, -7.5206e-01,  3.2874e+00, -2.5933e+00,\n",
            "        -1.1683e+00,  2.0443e-01, -8.3108e-01,  5.1256e+00, -6.4861e-01,\n",
            "         1.9697e+00, -1.9647e+00, -9.8110e-01, -7.2999e-01, -7.4806e-02,\n",
            "         1.8084e+00, -1.9307e-01, -2.6292e+00, -1.2675e+00,  2.2852e-01,\n",
            "        -6.7074e-01, -9.9861e-03,  1.0909e+00, -9.1979e-01,  4.2246e-01,\n",
            "        -2.0170e+00, -1.7340e+00, -8.8717e-01,  3.1530e-02,  3.6365e-01,\n",
            "        -8.1218e-01, -1.3963e-01, -2.1022e+00,  2.2275e-01, -3.5423e-01,\n",
            "        -1.0872e+00,  2.7459e+00,  2.2744e-01,  4.9171e-01, -5.0048e-01,\n",
            "        -4.5103e-01, -4.1779e-01, -1.3582e+00,  9.5779e-01,  2.1623e-01,\n",
            "         2.9582e-01, -6.6868e-01, -3.1478e-01, -3.7956e-01, -1.1151e+00,\n",
            "         5.8302e-01,  2.1623e-01,  2.9582e-01, -6.6868e-01, -3.1478e-01,\n",
            "         5.3348e-02,  1.8003e-01,  1.0823e+00, -5.2413e-01, -2.4627e+00,\n",
            "        -4.6004e+00,  2.3140e-01, -1.2363e-01,  6.6528e-02,  1.0616e+00,\n",
            "        -1.1898e+00,  1.1383e+00, -3.2431e+00, -6.0777e-01, -1.2695e-01,\n",
            "         1.4813e-01,  1.0209e+00, -9.9566e-01, -1.1173e+00, -2.4453e+00,\n",
            "        -1.9656e-02,  1.1850e+00, -8.7534e-01,  1.2209e+00, -1.6464e-01,\n",
            "         1.4735e-01, -1.5787e+00, -2.0794e-01,  9.5406e-01, -8.9989e-01,\n",
            "         9.8122e-01, -9.1810e-02,  1.8752e-05, -2.0111e+00,  4.6533e-02,\n",
            "         7.4340e-01, -8.7214e-01,  9.3822e-01, -9.1810e-02,  1.8752e-05,\n",
            "        -2.0111e+00,  4.6533e-02, -6.9789e-01, -1.0622e+00, -4.0015e+00,\n",
            "        -2.2772e-01, -9.0137e-01, -8.6865e-02, -6.4577e-01, -8.4289e-01,\n",
            "        -5.0504e+00, -7.6760e-01, -1.0878e+00, -9.9341e-02, -2.7232e-01,\n",
            "        -5.0983e-01, -2.3223e+00, -1.2411e-01, -9.2067e-01, -2.6397e-01,\n",
            "        -2.8091e-01, -4.6601e-01, -1.7976e+00, -2.9850e+00,  3.3218e-01,\n",
            "         3.0848e-01,  5.3117e-02,  1.7382e-02,  3.0083e-01, -8.6572e-02,\n",
            "         2.3697e-03, -1.4681e-01, -3.5202e-02,  1.1367e-02,  1.2291e-01,\n",
            "         8.2338e-01, -1.8144e-02,  8.9264e-02, -8.0171e-01, -3.4748e-01,\n",
            "        -2.4481e+00, -5.8091e-01, -8.1995e-01,  5.8069e-02, -9.8418e-02,\n",
            "        -3.5069e-01, -7.7690e-01, -8.7870e-01, -7.0936e-01,  1.5209e-01,\n",
            "         7.8006e-02, -3.3300e-01, -3.4534e-01, -8.7870e-01, -7.0936e-01,\n",
            "         1.5209e-01, -2.0022e-01, -6.2098e-01, -7.6427e-01, -5.2910e+00,\n",
            "         2.8485e-01,  3.9695e-01,  1.3633e-01,  8.0536e-02,  5.8304e-01,\n",
            "         1.1783e+00,  5.5224e-01,  2.5842e-02, -5.2685e-02,  1.3507e-01,\n",
            "         3.8591e-02,  7.2679e-01, -4.5078e-02, -9.8700e-03, -1.7657e-01,\n",
            "        -8.0124e-01, -2.3996e-01, -1.0018e+00, -4.3190e-01,  2.1338e-01,\n",
            "         9.2150e-02, -5.9389e-01,  9.7896e-01, -7.7183e-01, -3.5517e-01,\n",
            "         2.7335e-01,  1.5933e-01, -5.1679e-01,  1.0416e+00, -7.7183e-01,\n",
            "        -3.5517e-01,  2.7335e-01])\n"
          ]
        }
      ],
      "source": [
        "# check correct scaling\n",
        "idx = random.randint(0, dataset_len)\n",
        "print(raw_expert_observations[idx])\n",
        "print(expert_dataset.__getitem__(idx)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "56a9ee4c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shapes:\n",
            "actions shape: torch.Size([36])\n",
            "observations shape: torch.Size([197])\n"
          ]
        }
      ],
      "source": [
        "# Data Loaders\n",
        "\n",
        "batch_size = 128\n",
        "train_prop = 0.7\n",
        "train_size = int(train_prop * len(expert_dataset))\n",
        "test_size = int(0.2 * len(expert_dataset))\n",
        "val_size = int(0.1 * len(expert_dataset))\n",
        "train_expert_dataset, test_expert_dataset,val_expert_dataset = random_split(expert_dataset, [train_size, test_size,val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_expert_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader( dataset=val_expert_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"actions shape: {}\".format(train_loader.dataset.__getitem__(0)[1].shape))\n",
        "print(\"observations shape: {}\".format(train_loader.dataset.__getitem__(0)[0].shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae4e82b",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "94873ce1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy net: BCOAgentFC(\n",
            "  (fc1): Linear(in_features=197, out_features=394, bias=True)\n",
            "  (bn1): BatchNorm1d(394, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU()\n",
            "  (fc2): Linear(in_features=394, out_features=36, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Policy Agent\n",
        "import bco_agents as bco\n",
        "\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = bco.BCOAgentFC(obs_space, action_space, h_size=obs_space*2).to(device)\n",
        "\n",
        "print(\"Policy net: {}\".format(policy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8afe7403",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Policy net: BCO_cnn(\n",
            "  (conv1): Conv1d(1, 36, kernel_size=(5,), stride=(2,), padding=(1,))\n",
            "  (conv2): Conv1d(36, 36, kernel_size=(3,), stride=(2,), padding=(2,))\n",
            "  (fc1): Linear(in_features=1800, out_features=72, bias=True)\n",
            "  (fc2): Linear(in_features=72, out_features=36, bias=True)\n",
            "  (LRelu): LeakyReLU(negative_slope=0.01)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Policy Agent\n",
        "\n",
        "import bco_cnn as bco_cnn\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = bco_cnn.BCO_cnn(obs_space, action_space).to(device) # fix add hidden layer size\n",
        "\n",
        "print(\"Policy net: {}\".format(policy))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36fd7301",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "09e78876",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train functions\n",
        "\n",
        "def train(\n",
        "        policy,\n",
        "        train_epochs,\n",
        "        train_loader, \n",
        "        val_loader,\n",
        "        optimizer,\n",
        "        loss_criterion,\n",
        "        scheduler,\n",
        "        thrashold\n",
        "    ):\n",
        "\n",
        "    policy.train()\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    unused_val = 0\n",
        "\n",
        "    with tqdm(total=train_epochs, leave=True) as pbar:\n",
        "        for epoch in range(train_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "\n",
        "                if policy.name == 'bco-cnn':\n",
        "                    obs = obs.unsqueeze(1)\n",
        "                \n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                student_action = policy(obs)\n",
        "                expert_action = expert_action.float()\n",
        "\n",
        "                loss = loss_criterion(student_action, expert_action)\n",
        "                # loss.register_hook(lambda grad: print(grad))\n",
        "                loss.backward()\n",
        "                # print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "                if not loss.item() == torch.inf: \n",
        "                    epoch_loss += loss.item()\n",
        "                    optimizer.step()\n",
        "                    \n",
        "\n",
        "                else:\n",
        "                    unused_val += 1\n",
        "                    print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                    print(f'obs -> {obs}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'expert_action -> {expert_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'student_action -> {student_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    return expert_action,student_action\n",
        "\n",
        "                res = print_gradients(policy)\n",
        "                \n",
        "                if torch.isnan(student_action).any(): \n",
        "                    print('e successo')\n",
        "                    break\n",
        "\n",
        "                if res == 1: \n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(student_action.shape)\n",
        "                    for i, ea in enumerate(expert_action):\n",
        "                        if not np.isfinite(ea).all():\n",
        "                            print(i+64)\n",
        "                            print(f'expert_action -> {ea}')\n",
        "\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'Max expert_action -> {expert_action.max()}')\n",
        "                    print(f'Min expert_action -> {expert_action.min()}')\n",
        "                    print(f'Max student_action -> {student_action.max()}')\n",
        "                    print(f'Min student_action -> {student_action.min()}')\n",
        "                    break\n",
        "                \n",
        "            # deactivate scheduler\n",
        "            # if epoch % 50 == 0 and epoch < thrashold :\n",
        "            #     scheduler.step()\n",
        "            \n",
        "            # compute accuracy\n",
        "            # print(\"Epoch {}\".format(epoch))\n",
        "            # print(\"Train Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "            # validation(test_loader,policy,loss_criterion,num_epochs=eval_epochs)\n",
        "            # print(\"Unused Loss: {}\".format(unused_val))\n",
        "            t_loss = epoch_loss/(batch_idx+1)\n",
        "            v_loss = validation(val_loader, policy, loss_criterion)\n",
        "            epoch_loss = 0\n",
        "            unused_val = 0\n",
        "            pbar.set_postfix(train=t_loss, validation=v_loss)\n",
        "            pbar.update(1)\n",
        "            \n",
        "        \n",
        "        print(\"###############################################################################\\n\")\n",
        "        print(\"Train Loss: {}\".format(t_loss))\n",
        "        print(\"Validation Loss: {}\".format(v_loss))\n",
        "        print(\"###############################################################################\\n\")\n",
        "\n",
        "\n",
        "def validation(loader, policy,loss_criterion):\n",
        "    policy.eval()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        obs, expert_action = data.to(device), target.to(device)\n",
        "        obs = obs.float()\n",
        "        if policy.name == 'bco-cnn':\n",
        "            obs = obs.unsqueeze(1)\n",
        "        student_action = policy(obs)\n",
        "        loss = loss_criterion(student_action, expert_action)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss/(batch_idx+1)\n",
        "\n",
        "def print_gradients(policy):\n",
        "    for name, param in policy.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if torch.isnan(param.grad).any(): \n",
        "                return 1#break\n",
        "            # print(f\"Gradient of {name}: {param.grad}\")\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1d8a59c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2500/2500 [02:48<00:00, 14.81it/s, train=0.00162, validation=0.00214]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###############################################################################\n",
            "\n",
            "Train Loss: 0.0016199027921891575\n",
            "Validation Loss: 0.0021418428281322122\n",
            "###############################################################################\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train module\n",
        "\n",
        "loss_criterion = nn.MSELoss()\n",
        "# Create a learning rate scheduler\n",
        "step_size = 80\n",
        "gamma = 0.3\n",
        "optimizer =  optim.Adam(policy.parameters(), lr=1e-3)\n",
        "optimizer =  optim.SGD(policy.parameters(), lr=1e-3,momentum=0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "eval_epochs = 5\n",
        "\n",
        "train(policy, \n",
        "      train_epochs=2500, \n",
        "      train_loader=train_loader, \n",
        "      val_loader=val_loader,\n",
        "      optimizer=optimizer,\n",
        "      loss_criterion=loss_criterion,\n",
        "      scheduler=scheduler,\n",
        "      thrashold = 100\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f15e40",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e6143335",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(policy, test_loader,loss_criterion):\n",
        "    policy.eval()   \n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "\n",
        "        obs, expert_action = data.to(device), target.to(device)\n",
        "        obs = obs.float()\n",
        "        \n",
        "        if policy.name == 'bco-cnn':\n",
        "            obs = obs.unsqueeze(1)\n",
        "\n",
        "        student_action = policy(obs)\n",
        "        expert_action = expert_action.float()\n",
        "\n",
        "        loss = loss_criterion(student_action, expert_action)\n",
        "\n",
        "        if not loss.item() == torch.inf: \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        if torch.isnan(student_action).any(): \n",
        "            print('e successo')\n",
        "            break\n",
        "        \n",
        "    t_loss = epoch_loss/(batch_idx+1)\n",
        "    epoch_loss = 0\n",
        "            \n",
        "    \n",
        "    print(\"Test Loss: {}\".format(t_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "99284dae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.0024583286023698745\n"
          ]
        }
      ],
      "source": [
        "test(policy=policy, test_loader=test_loader, loss_criterion=loss_criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a1c18b04",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "real action: tensor([-0.3407,  0.0575, -0.0633,  0.4559, -0.3676, -0.0539,  0.2109,  0.5210,\n",
            "         0.4833,  0.0087, -0.4612,  0.5249, -0.2025, -0.4031,  0.0756,  0.1666,\n",
            "         0.4129,  0.5274, -0.0903,  0.2039,  0.2079,  0.3886,  0.7169,  0.0659,\n",
            "        -0.0135,  0.5697, -0.4891, -0.1242, -0.0457,  0.0159,  0.1940,  0.4291,\n",
            "         0.1285, -0.2849,  0.3103,  0.1618])\n",
            "our action: [-0.24804996  0.05207529 -0.10330974  0.40238184 -0.41371584 -0.07148968\n",
            "  0.20436227  0.54680246  0.45014328 -0.01753886 -0.46559608  0.52920425\n",
            " -0.17799583 -0.47082734  0.08399461  0.17068592  0.41985917  0.5196824\n",
            " -0.10476074  0.21129487  0.21357316  0.39600885  0.7914258   0.05508422\n",
            " -0.01567679  0.5620211  -0.45917904 -0.08325265 -0.05579152 -0.01537449\n",
            "  0.17497064  0.37968275  0.15011017 -0.29302117  0.29794413  0.166696  ]\n",
            "real action: tensor([-0.2683,  0.0535, -0.0365,  0.5007,  0.4285,  0.3690,  0.0562,  0.4159,\n",
            "         0.9843, -0.0570, -0.0247,  0.5013, -2.1507, -0.2433,  0.0571,  0.0461,\n",
            "         0.3747,  0.7204, -0.0179,  0.0133,  0.2284,  0.5232,  0.1131, -0.0245,\n",
            "         0.1642,  0.6389, -0.6970, -2.3314, -0.2313, -0.1166,  0.6029,  0.9292,\n",
            "         0.1055, -0.0791,  0.2959, -0.7021])\n",
            "our action: [-0.22948729  0.02690321 -0.07601058  0.3226651   0.43388492  0.3548899\n",
            "  0.05927168  0.34832624  0.95558816 -0.00736842 -0.07458823  0.45840314\n",
            " -2.1236136  -0.4330042   0.11768948  0.0933596   0.47112018  0.8463892\n",
            " -0.07637791  0.01260636  0.26776016  0.61753124 -0.00613786 -0.02147023\n",
            "  0.11271044  0.5283736  -0.76322865 -2.3287354  -0.1858337  -0.133416\n",
            "  0.54175025  0.84781206  0.01882686 -0.16584581  0.31449452 -0.55473506]\n",
            "real action: tensor([-0.0943, -0.2084,  0.1103,  0.6826, -0.0642,  0.3645,  0.0561,  0.6009,\n",
            "         3.0192, -0.1263, -0.1172,  0.9771, -0.6620, -0.5643,  0.2281, -0.0331,\n",
            "         0.3334,  0.8094, -0.1845,  0.3445,  0.0331,  0.6362,  2.9516,  0.0297,\n",
            "         0.0286,  0.8728, -1.0242, -0.5441, -0.1656,  0.3948,  0.3984,  1.5906,\n",
            "         0.3649, -0.5577,  0.2648,  0.8522])\n",
            "our action: [-0.0748622  -0.19492148  0.08890716  0.667644   -0.02433299  0.35273764\n",
            "  0.07616359  0.6183559   2.834652   -0.09619748 -0.10964806  0.9465742\n",
            " -0.65921843 -0.5864104   0.19764195 -0.04466609  0.28900185  0.7902854\n",
            " -0.18740195  0.37591746  0.0405225   0.6799936   2.881354    0.04742289\n",
            "  0.03332403  0.87980926 -0.96768975 -0.5495274  -0.15680498  0.3953284\n",
            "  0.36034146  1.4796724   0.34905326 -0.5518256   0.28864846  1.0030116 ]\n",
            "real action: tensor([-0.6027, -0.1316,  0.0454,  0.6132, -0.2865,  0.0154,  0.1160,  0.7068,\n",
            "         1.1386, -0.0283, -0.2248,  0.7014, -1.1165, -1.3210, -0.0103,  0.1071,\n",
            "         0.4097,  1.1339, -0.0637,  0.1340,  0.2122,  0.4992,  1.3794,  0.0262,\n",
            "         0.0128,  0.7445, -1.0526, -1.6639, -0.0467,  0.0840,  0.2220,  1.4741,\n",
            "         0.1992, -0.1150,  0.4563,  0.4378])\n",
            "our action: [-5.7142401e-01 -1.0293037e-01  3.6397152e-02  6.2512243e-01\n",
            " -2.9546756e-01 -5.9591457e-03  1.0523762e-01  6.8596500e-01\n",
            "  1.2733343e+00  6.3161552e-04 -2.7290979e-01  6.9723558e-01\n",
            " -1.2098775e+00 -1.2736977e+00 -1.3199341e-02  1.0044242e-01\n",
            "  4.4246435e-01  1.1480016e+00 -5.8075003e-02  1.5507455e-01\n",
            "  2.5610402e-01  5.2349108e-01  1.3717438e+00  4.9929921e-02\n",
            "  6.8615004e-03  7.5608742e-01 -1.0515130e+00 -1.6930481e+00\n",
            " -1.6104698e-02  1.1017763e-01  1.8593581e-01  1.4830837e+00\n",
            "  1.9814441e-01 -1.0918458e-01  4.7938293e-01  3.9595127e-01]\n",
            "real action: tensor([-0.5052, -0.0065, -0.0183,  0.5780, -0.2526, -0.0062,  0.1694,  0.6087,\n",
            "         0.8988, -0.0268, -0.3146,  0.6352, -1.0351, -0.9710,  0.0232,  0.1345,\n",
            "         0.4146,  0.8552, -0.0264,  0.1954,  0.2502,  0.5488,  0.9643,  0.0392,\n",
            "         0.0669,  0.6604, -0.9052, -1.0699, -0.0607,  0.0493,  0.2030,  1.1531,\n",
            "         0.1656, -0.2453,  0.4575,  0.3412])\n",
            "our action: [-0.47897887 -0.0310178  -0.02525117  0.57685506 -0.2733922  -0.00243647\n",
            "  0.18401887  0.6144783   0.85705763 -0.04872388 -0.32470825  0.64212847\n",
            " -0.9509367  -1.0002606   0.00746413  0.10647906  0.39596462  0.82383746\n",
            " -0.05443995  0.20928352  0.25519785  0.54813653  1.0461966   0.060706\n",
            "  0.09285071  0.6634413  -0.89487106 -1.0468917  -0.04833729  0.02157089\n",
            "  0.22149879  1.1398866   0.1691496  -0.23395331  0.45782724  0.31448707]\n",
            "real action: tensor([ 0.1376,  0.1495, -0.0240,  0.3076, -0.2874, -0.0510,  0.1134,  0.3622,\n",
            "        -0.2561, -0.0571, -0.4546,  0.3743,  0.6959, -1.2596,  0.0905,  0.0267,\n",
            "         0.5497,  1.4928, -0.3981, -0.1599,  0.0079, -0.4853,  0.1555,  0.0240,\n",
            "        -0.3460,  0.4632,  0.2944, -1.4020, -0.1058, -0.0758,  0.3612,  1.7846,\n",
            "         0.4668, -0.1824, -0.2138, -0.2114])\n",
            "our action: [ 1.2546176e-01  1.5573542e-01 -3.3790402e-02  2.7919605e-01\n",
            " -2.9690003e-01  7.2068721e-04  5.8552813e-02  3.5864341e-01\n",
            " -2.6749220e-01 -6.3924156e-02 -4.6106046e-01  3.6551294e-01\n",
            "  6.9191110e-01 -1.3109183e+00  7.6899812e-02  2.1674640e-02\n",
            "  5.7301044e-01  1.4964628e+00 -3.9589089e-01 -1.6528128e-01\n",
            "  3.4762096e-02 -5.4947370e-01  1.3538060e-01  1.3472762e-02\n",
            " -3.3629984e-01  4.5757088e-01  2.5739136e-01 -1.3834548e+00\n",
            " -9.9293850e-02 -5.1466968e-02  3.5846487e-01  1.8089406e+00\n",
            "  4.5272332e-01 -1.8450239e-01 -2.0446560e-01 -2.8067437e-01]\n",
            "real action: tensor([ 0.1375,  0.1334, -0.0428,  0.3885, -0.5584,  0.0266,  0.0740,  0.4007,\n",
            "         0.3335, -0.0538, -0.3564,  0.5159, -0.5553, -1.5094,  0.0670,  0.0528,\n",
            "         0.5468,  1.6886, -0.4026, -0.2210, -0.1313, -1.2104,  1.3215, -0.0812,\n",
            "        -0.1540,  0.5519, -0.9029, -0.6630, -0.1888, -0.0778,  0.3059,  1.5134,\n",
            "         0.3523, -0.0635, -0.2785, -0.8349])\n",
            "our action: [ 0.09636666  0.117569   -0.02197099  0.41385794 -0.47785616  0.0338058\n",
            "  0.14011417  0.4230473   0.25453672 -0.02483616 -0.3159836   0.54105574\n",
            " -0.75570107 -1.5537086   0.10362563  0.04688835  0.553311    1.5466061\n",
            " -0.39746684 -0.21811755 -0.12864423 -1.2375059   1.1500057  -0.02600015\n",
            " -0.16532972  0.52784735 -0.9943805  -0.8713125  -0.14009191 -0.03895092\n",
            "  0.28712115  1.5478542   0.34457767 -0.09786686 -0.17006168 -0.7185931 ]\n",
            "real action: tensor([ 0.1389,  0.1091, -0.0307,  0.3129, -0.2512, -0.0087,  0.0999,  0.3018,\n",
            "        -0.1728, -0.0219, -0.4019,  0.3266,  0.3274, -0.9430,  0.0719,  0.0081,\n",
            "         0.5195,  1.0536, -0.3168, -0.0650,  0.0986, -0.0680, -0.0885, -0.0228,\n",
            "        -0.3455,  0.4091,  0.3288, -1.2498, -0.1239, -0.0259,  0.3237,  1.3933,\n",
            "         0.3774, -0.2058, -0.0851, -0.0022])\n",
            "our action: [ 9.0715349e-02  9.3888193e-02 -5.4194629e-03  2.9920056e-01\n",
            " -2.5857824e-01 -5.0302595e-04  1.0208632e-01  2.9350227e-01\n",
            " -1.9105957e-01 -2.3917407e-03 -4.1208038e-01  2.9682958e-01\n",
            "  3.5860810e-01 -9.9582690e-01  4.5714188e-02  9.7867921e-03\n",
            "  5.1950222e-01  1.1364132e+00 -3.5157025e-01 -7.3868737e-02\n",
            "  1.2148154e-01 -9.2935935e-02 -7.7240095e-02 -2.6707951e-02\n",
            " -3.2419196e-01  3.7652135e-01  3.2464093e-01 -1.1981399e+00\n",
            " -1.2744802e-01 -3.3602592e-02  3.3086571e-01  1.4517730e+00\n",
            "  3.6888975e-01 -1.9924662e-01 -9.7762227e-02 -1.2335107e-02]\n",
            "real action: tensor([ 0.0757, -0.0322,  0.1895,  0.4959, -0.3880,  0.3160,  0.0858,  0.6293,\n",
            "         2.0672, -0.2044, -0.1110,  0.7647, -0.0750, -0.7043,  0.2781, -0.0787,\n",
            "         0.4198,  0.3703, -0.2506, -0.0506,  0.2547,  1.6784,  2.5765, -0.1293,\n",
            "        -0.0929,  0.7663, -0.2720, -0.4333, -0.2266,  0.1006,  0.4176,  1.2159,\n",
            "         0.1465, -0.4730,  0.1064,  0.9509])\n",
            "our action: [-0.04562391 -0.04110152  0.23212165  0.46153736 -0.41701603  0.33739936\n",
            "  0.09912445  0.59296054  1.9932826  -0.19408292 -0.03447599  0.78606653\n",
            " -0.09354857 -0.59039146  0.25619766 -0.09275156  0.4033263   0.51520884\n",
            " -0.28128305 -0.03039329  0.23988074  1.6313013   2.393202   -0.11870766\n",
            " -0.08429063  0.7212502  -0.22113304 -0.4263702  -0.27127445  0.13430797\n",
            "  0.43342853  1.1002954   0.1717939  -0.4880253   0.11531073  0.95216393]\n",
            "real action: tensor([ 0.4738,  0.2167, -0.0268,  0.6976,  0.4683,  0.2018,  0.3619,  0.3127,\n",
            "         1.7096, -0.0645, -0.2702,  0.6081, -1.3920, -0.5419,  0.1943,  0.0378,\n",
            "         0.5932,  2.9385, -0.3356,  0.2305,  0.6045, -0.2531, -1.1422, -0.1840,\n",
            "        -0.0429,  0.7978,  0.2847, -0.9308, -0.1510,  0.0108,  0.4406,  3.1406,\n",
            "         0.3722, -0.4394,  0.6357,  1.0185])\n",
            "our action: [ 4.3756044e-01  1.8435240e-01 -4.2242993e-02  7.1968204e-01\n",
            "  4.5657194e-01  2.2199741e-01  3.6258882e-01  3.3249632e-01\n",
            "  1.8047484e+00 -5.8436073e-02 -2.8489372e-01  5.9989995e-01\n",
            " -1.4702382e+00 -5.6168866e-01  1.5939717e-01  2.8706424e-02\n",
            "  5.8333415e-01  2.9799683e+00 -3.2673082e-01  2.4086328e-01\n",
            "  5.7551485e-01 -2.6865366e-01 -1.1239481e+00 -1.8659569e-01\n",
            " -6.8490386e-02  8.1189573e-01  2.3373263e-01 -9.5095176e-01\n",
            " -1.3504064e-01 -2.4819328e-03  4.6004415e-01  3.2292089e+00\n",
            "  3.5201296e-01 -4.2189860e-01  6.1287427e-01  1.0003142e+00]\n",
            "real action: tensor([-1.0547e+00, -9.9471e-02,  6.3954e-02,  6.6353e-01, -1.6359e-01,\n",
            "         2.8915e-01,  3.2590e-02,  6.0793e-01,  4.4876e+00, -1.3519e-01,\n",
            "         8.0599e-02,  9.2177e-01, -1.1075e+00, -3.5403e-01,  2.2086e-01,\n",
            "         8.2238e-04,  4.0171e-01,  1.1987e+00, -2.8132e-01,  9.3973e-02,\n",
            "         2.6948e-03,  4.7245e-01,  4.8541e+00, -2.6948e-02,  1.2581e-01,\n",
            "         8.3391e-01, -1.5482e+00, -8.3042e-01, -1.7655e-01,  4.5002e-02,\n",
            "         3.9659e-01,  1.5595e+00,  2.4743e-01, -2.2677e-01,  2.7231e-01,\n",
            "         7.3944e-01])\n",
            "our action: [-1.1587986  -0.14671476  0.02865795  0.62274545 -0.11954819  0.27362353\n",
            "  0.11112206  0.62321323  4.658673   -0.17451951 -0.00759996  0.87403005\n",
            " -0.9106108  -0.33488065  0.24631247 -0.01009097  0.43869442  1.2086338\n",
            " -0.28383374  0.08632548 -0.02770165  0.298749    4.802764   -0.01916415\n",
            "  0.19700569  0.82467234 -1.4506134  -0.8803128  -0.24664257  0.01619473\n",
            "  0.409299    1.5625179   0.36661732 -0.30227602  0.33114994  0.6569973 ]\n",
            "real action: tensor([-0.2306, -0.0697,  0.0185,  0.3860,  0.3031,  0.1887,  0.0594,  0.3664,\n",
            "         1.0716, -0.0147,  0.0607,  0.4847, -1.0971, -0.5069,  0.0150,  0.0820,\n",
            "         0.2884,  0.2658,  0.0029, -0.1824, -0.0059,  0.4941,  0.9310, -0.0475,\n",
            "         0.1310,  0.5353, -0.9666, -1.7681, -0.1508, -0.1849,  0.5000,  1.2282,\n",
            "         0.1234,  0.2501,  0.1641, -0.9332])\n",
            "our action: [-0.3122447  -0.08058958  0.0500325   0.401819    0.2907142   0.22422412\n",
            "  0.0847394   0.3941154   1.1303103  -0.03670419  0.06801864  0.5056804\n",
            " -1.1235423  -0.5293389   0.03852535  0.07705466  0.28958598  0.36973166\n",
            " -0.01889142 -0.20321496 -0.00378746  0.4074495   0.9933386  -0.06010849\n",
            "  0.10464381  0.54848915 -0.8894557  -1.7093004  -0.16143973 -0.17384204\n",
            "  0.48599982  1.2073065   0.11154997  0.22495072  0.13361531 -0.99027586]\n",
            "real action: tensor([-9.2676e-04,  1.4247e-01, -2.0928e-02,  6.8432e-01,  8.9007e-01,\n",
            "         2.9661e-01,  3.0622e-01,  4.0534e-01,  1.2058e+00, -9.8968e-02,\n",
            "        -1.8355e-01,  6.0602e-01, -2.0112e+00, -5.8488e-01,  1.5339e-01,\n",
            "         5.1147e-02,  4.9422e-01,  2.4966e+00, -1.3544e-01,  3.6542e-01,\n",
            "         5.9445e-01, -3.9379e-01, -9.1500e-01, -1.7089e-01,  4.2612e-02,\n",
            "         7.5713e-01, -3.1395e-01, -1.2708e+00, -1.2517e-01, -5.5874e-03,\n",
            "         4.4900e-01,  2.4745e+00,  2.0293e-01, -5.7470e-01,  6.2859e-01,\n",
            "         8.9728e-01])\n",
            "our action: [ 0.02873446  0.1397629   0.00653129  0.6872339   0.8340902   0.3266022\n",
            "  0.3147624   0.4212064   1.2437074  -0.09052988 -0.16493234  0.5870086\n",
            " -1.9215341  -0.6092956   0.12752482  0.00378662  0.4857695   2.4607098\n",
            " -0.11668318  0.3277914   0.6083928  -0.3730096  -0.95064163 -0.16062036\n",
            "  0.01114852  0.7841667  -0.27360827 -1.2619314  -0.14558423  0.01263296\n",
            "  0.4705064   2.455697    0.19040662 -0.5684506   0.6376527   0.78677356]\n",
            "real action: tensor([-1.1211, -0.0262, -0.0471,  0.5802, -0.1444,  0.0092,  0.1800,  0.6389,\n",
            "         2.6760, -0.2287,  0.1480,  0.8885, -3.4005, -0.0936, -0.0541, -0.2243,\n",
            "         0.1825,  1.0514, -0.2948, -0.0679,  0.3064,  1.6614,  2.2822, -0.0899,\n",
            "         0.1366,  0.5593, -2.7672, -0.3935, -0.2297,  0.0119,  0.4532,  1.1489,\n",
            "         0.2481,  0.0836,  0.3124,  0.6635])\n",
            "our action: [-1.1390160e+00 -3.2768160e-02 -6.0168527e-02  5.6393993e-01\n",
            " -1.4421888e-01  1.9144192e-03  1.4267096e-01  6.1641908e-01\n",
            "  2.5004299e+00 -2.2150850e-01  1.0844987e-01  8.3952975e-01\n",
            " -3.2164490e+00 -4.8629329e-02 -9.4069377e-02 -1.9011927e-01\n",
            "  1.5591291e-01  1.0343454e+00 -2.7151781e-01 -8.2761683e-03\n",
            "  3.2174319e-01  1.6296179e+00  2.4306514e+00 -5.7088722e-02\n",
            "  1.7824832e-01  5.3083080e-01 -2.7093093e+00 -4.5100927e-01\n",
            " -1.7778283e-01  2.9238258e-02  4.5260620e-01  1.1054599e+00\n",
            "  2.7825767e-01  6.7113683e-02  3.8385311e-01  5.4447031e-01]\n",
            "real action: tensor([-3.8612e-01, -1.8506e-01,  1.5690e-02,  6.3937e-01,  6.6823e-02,\n",
            "         2.9086e-01,  5.4307e-03,  6.8204e-01,  3.0378e+00, -1.0658e-01,\n",
            "        -9.5299e-02,  9.7499e-01, -9.8318e-01, -3.4236e-01,  7.4659e-02,\n",
            "        -3.6095e-02,  2.9756e-01,  9.8674e-01, -1.8927e-01,  3.2858e-01,\n",
            "        -1.8868e-02,  2.3595e-03,  3.0035e+00, -2.0060e-02,  6.4739e-02,\n",
            "         7.7465e-01, -1.1585e+00, -8.1362e-01, -9.0357e-02,  3.6073e-01,\n",
            "         4.3594e-01,  1.7125e+00,  2.4280e-01, -4.5036e-01,  2.2054e-01,\n",
            "         1.3405e+00])\n",
            "our action: [-0.4265784  -0.18947539  0.05410159  0.6496776   0.02934255  0.30171838\n",
            "  0.01740775  0.6777373   2.8894794  -0.10796542 -0.07191182  0.9893899\n",
            " -1.0477977  -0.3465879   0.06419496 -0.04236443  0.3171781   1.0571554\n",
            " -0.21082374  0.29983175 -0.03262954  0.04893848  2.938949   -0.07533339\n",
            "  0.08337527  0.7998617  -1.3163855  -0.8378895  -0.12633273  0.35556072\n",
            "  0.44523713  1.693042    0.26297644 -0.44820416  0.2272054   1.2515063 ]\n",
            "real action: tensor([-0.3141, -0.0197,  0.0170,  0.4299,  0.4691,  0.2741,  0.0765,  0.3882,\n",
            "         1.1209, -0.0451,  0.0456,  0.4056, -1.4533, -0.9623,  0.0115,  0.0411,\n",
            "         0.2848,  0.5688,  0.0275, -0.0397,  0.1762,  0.7017,  0.4385, -0.0448,\n",
            "         0.1319,  0.4800, -0.8352, -2.1331, -0.1774, -0.1570,  0.5493,  0.7450,\n",
            "         0.0843,  0.0151,  0.2558, -0.3745])\n",
            "our action: [-0.29882103 -0.02889863  0.02649222  0.45750192  0.4731735   0.26474985\n",
            "  0.06872608  0.40042353  1.0977217  -0.05329477  0.03727468  0.410999\n",
            " -1.3654794  -0.9074786  -0.00398831  0.059696    0.28002414  0.51186436\n",
            "  0.02479517 -0.02138387  0.17665601  0.7029832   0.4968959  -0.06608608\n",
            "  0.10739759  0.5075365  -0.8036858  -2.0720053  -0.18380834 -0.13273859\n",
            "  0.55659026  0.6962662   0.07848535  0.02007762  0.25048897 -0.40685603]\n",
            "real action: tensor([-0.5187, -0.3240,  0.1266,  0.7945, -0.2324,  0.0753,  0.1477,  0.8210,\n",
            "         1.9690, -0.0647, -0.1700,  0.7718, -1.1682, -1.4864, -0.0207,  0.0478,\n",
            "         0.4453,  1.1466, -0.1380,  0.1695,  0.2954,  0.2851,  1.4624, -0.0804,\n",
            "        -0.0916,  0.8607, -1.0842, -2.1259, -0.1217,  0.1213,  0.2651,  1.2767,\n",
            "         0.2241, -0.0740,  0.5306,  0.3089])\n",
            "our action: [-0.53710985 -0.27922755  0.08322886  0.75052845 -0.28510404  0.03475729\n",
            "  0.15766068  0.8205513   1.9367821  -0.04003016 -0.19075945  0.78943026\n",
            " -1.1000147  -1.499271    0.00992716  0.07341199  0.49600285  1.2235572\n",
            " -0.13718644  0.21486025  0.27296633  0.38533124  1.5436503  -0.11350098\n",
            " -0.09426237  0.8392207  -0.964734   -2.1314487  -0.11955327  0.10445637\n",
            "  0.255716    1.3131288   0.25579977 -0.06114715  0.52420264  0.23703435]\n",
            "real action: tensor([-0.2999,  0.0234, -0.0283,  0.3577, -0.0700, -0.0578,  0.0187,  0.5115,\n",
            "         1.5150, -0.0247,  0.0386,  0.7551, -1.5263,  0.1966,  0.0038,  0.1149,\n",
            "         0.3030,  1.3690, -0.2522, -0.3829, -0.3690, -0.9220,  1.5580, -0.0174,\n",
            "         0.1375,  0.6266, -1.6246, -0.3811, -0.1285, -0.2796,  0.3067,  1.6384,\n",
            "         0.2318,  0.4008, -0.1035, -1.3746])\n",
            "our action: [-0.37780815  0.05064557 -0.03387778  0.33676517 -0.06508701 -0.05932396\n",
            " -0.00208724  0.4921466   1.5376675  -0.01123389  0.03714883  0.74891126\n",
            " -1.4561491   0.22418414  0.0227506   0.09272242  0.32608178  1.3813434\n",
            " -0.21549395 -0.36515447 -0.37968707 -0.9115682   1.5972072   0.00369563\n",
            "  0.10896844  0.63642573 -1.6005611  -0.32204154 -0.13838467 -0.26985613\n",
            "  0.31988415  1.5972052   0.2548492   0.38599372 -0.07687071 -1.3688062 ]\n",
            "real action: tensor([-0.6303, -0.2119,  0.0448,  0.7021, -0.1893,  0.0286,  0.1206,  0.7612,\n",
            "         1.0982, -0.0726, -0.2402,  0.6976, -1.2008, -1.4203, -0.0214,  0.0667,\n",
            "         0.4582,  1.3186, -0.0716,  0.1503,  0.2539,  0.2835,  1.1929, -0.0235,\n",
            "        -0.0375,  0.7593, -1.0670, -1.7844, -0.0765,  0.0790,  0.2297,  1.4338,\n",
            "         0.2013, -0.0817,  0.4584,  0.3045])\n",
            "our action: [-0.64182055 -0.21531433  0.02289992  0.6589876  -0.18391989  0.0103764\n",
            "  0.08303335  0.72626156  1.2276995  -0.03736965 -0.23229909  0.7451579\n",
            " -1.2045243  -1.3268248  -0.01696317  0.06762985  0.43347758  1.225159\n",
            " -0.08887591  0.16997422  0.25662878  0.37547356  1.2156911   0.00738802\n",
            " -0.04118761  0.8124275  -0.97625685 -1.8370131  -0.0699781   0.06347517\n",
            "  0.22402808  1.4879591   0.21333914 -0.11776157  0.47346961  0.31795612]\n",
            "real action: tensor([-0.3342,  0.0179,  0.0278,  0.4645,  0.6862,  0.2663,  0.1365,  0.4474,\n",
            "         1.0992, -0.1316,  0.0283,  0.4946, -1.6771, -1.0162,  0.0092,  0.0359,\n",
            "         0.2768,  1.0286,  0.0081,  0.1101,  0.3397,  0.3397,  0.2861, -0.0872,\n",
            "         0.1340,  0.5513, -0.7908, -1.6972, -0.1584, -0.1179,  0.5506,  0.9810,\n",
            "         0.0411, -0.2518,  0.3971, -0.0162])\n",
            "our action: [-0.36259812 -0.0310261   0.01906949  0.55899596  0.6796349   0.30979547\n",
            "  0.13618056  0.47633696  1.2594225  -0.09109948  0.02271714  0.4667864\n",
            " -1.8096535  -0.8848764   0.08140938  0.03895084  0.32979113  1.0449026\n",
            "  0.01583665  0.07918338  0.32737404  0.31289592  0.37319916 -0.05810418\n",
            "  0.15610081  0.59362787 -0.9340505  -1.6856673  -0.16571212 -0.10169157\n",
            "  0.51816887  0.9555117   0.03136968 -0.24664511  0.3942306   0.09338588]\n",
            "real action: tensor([-0.2331,  0.0600, -0.0338,  0.3265, -0.3905, -0.0358,  0.1317,  0.3564,\n",
            "         0.0916, -0.0135, -0.3922,  0.3500,  0.2090, -0.6039,  0.0411,  0.0536,\n",
            "         0.4322,  0.7603, -0.2374, -0.0187,  0.0904,  0.0821,  0.1417, -0.0826,\n",
            "        -0.2569,  0.3777,  0.0765, -0.3729, -0.1234, -0.0550,  0.2537,  0.9735,\n",
            "         0.2329, -0.1523, -0.0196, -0.1336])\n",
            "our action: [-0.18631123  0.05472146 -0.05629262  0.3384134  -0.38073725 -0.00564566\n",
            "  0.12372158  0.379882    0.0071361   0.00233714 -0.35066423  0.38534957\n",
            "  0.19517323 -0.5858468   0.06237197  0.05656654  0.41438568  0.69357926\n",
            " -0.22370434 -0.01995416  0.06778045  0.08217953  0.14270486 -0.06363915\n",
            " -0.2415744   0.39968678  0.04805528 -0.4341124  -0.12537348 -0.04872107\n",
            "  0.26363814  1.0014737   0.256259   -0.1449688  -0.01440787 -0.14016426]\n",
            "real action: tensor([-0.2817, -0.0342,  0.0185,  0.3858,  0.1934,  0.1094,  0.0588,  0.3994,\n",
            "         1.4894,  0.0138,  0.0464,  0.6085, -1.2707, -0.0910,  0.0152,  0.0887,\n",
            "         0.3064,  0.8445, -0.0949, -0.2977, -0.1670, -0.0374,  1.2647, -0.0527,\n",
            "         0.1297,  0.5947, -0.9705, -1.2507, -0.1372, -0.1909,  0.3908,  1.6475,\n",
            "         0.1547,  0.3900,  0.0718, -1.3768])\n",
            "our action: [-0.2978654  -0.03553516  0.01662267  0.3858667   0.20540242  0.09684826\n",
            "  0.05411468  0.40686432  1.4699616   0.01209328  0.07200643  0.6178059\n",
            " -1.2507315  -0.10348205 -0.01664614  0.10187802  0.30968103  0.85272264\n",
            " -0.10866406 -0.30752492 -0.14533067 -0.05929491  1.2593557  -0.0814386\n",
            "  0.14987904  0.5779558  -1.003176   -1.28662    -0.12761453 -0.19340348\n",
            "  0.40406147  1.632922    0.16835949  0.40589458  0.08466175 -1.3348837 ]\n",
            "real action: tensor([-0.0714,  0.0400, -0.0301,  0.4194, -0.3724, -0.0221,  0.1508,  0.5541,\n",
            "         0.4608, -0.0419, -0.4347,  0.4477,  0.0796, -0.4357,  0.1249,  0.1506,\n",
            "         0.4178,  0.5405, -0.1958,  0.0928,  0.2637,  0.5542,  0.3594,  0.0858,\n",
            "        -0.1317,  0.5492, -0.1794, -0.4184, -0.0334, -0.0354,  0.2591,  0.2983,\n",
            "         0.2085, -0.1548,  0.2856,  0.2690])\n",
            "our action: [-0.05350979  0.07833441 -0.0450343   0.4187646  -0.40833062 -0.06098089\n",
            "  0.1231886   0.55449694  0.50542843  0.02182831 -0.43385112  0.5002527\n",
            " -0.05250667 -0.48033535  0.08744726  0.11700473  0.398225    0.6237157\n",
            " -0.20715526  0.09453835  0.26065218  0.5111057   0.44400686  0.07330863\n",
            " -0.12355014  0.5430232  -0.15342124 -0.41031012 -0.00583635 -0.03707303\n",
            "  0.2613611   0.3190806   0.15939969 -0.13569868  0.2783569   0.25561607]\n",
            "real action: tensor([ 0.0156, -0.0175,  0.1814,  0.4663, -0.3722,  0.2629,  0.1381,  0.5950,\n",
            "         2.3621, -0.1894, -0.0569,  0.7852, -0.0530, -0.3625,  0.3316, -0.0402,\n",
            "         0.3521,  0.8912, -0.2460,  0.0256,  0.1526,  1.7696,  2.4916, -0.0636,\n",
            "        -0.0813,  0.7727, -0.3709, -0.1321, -0.1592,  0.1206,  0.3652,  1.2902,\n",
            "         0.1912, -0.4388,  0.1347,  0.9665])\n",
            "our action: [ 0.01659258 -0.02495158  0.14962521  0.48102236 -0.41468155  0.3183655\n",
            "  0.13444145  0.58759415  2.3268306  -0.17816585 -0.07009751  0.7810848\n",
            " -0.1114625  -0.45134634  0.2813134  -0.10860839  0.35690272  0.88533324\n",
            " -0.24996835 -0.014481    0.16403784  1.6975747   2.4170916  -0.02797228\n",
            " -0.06732661  0.7576335  -0.24200313 -0.17137    -0.1701377   0.13135383\n",
            "  0.39392394  1.3075993   0.20020203 -0.43058407  0.1233938   0.98023903]\n",
            "real action: tensor([-0.2230,  0.0663, -0.0364,  0.3302, -0.3628, -0.0382,  0.1230,  0.3542,\n",
            "         0.0502, -0.0150, -0.3889,  0.3477,  0.1785, -0.5633,  0.0529,  0.0522,\n",
            "         0.4395,  0.7875, -0.2383, -0.0164,  0.1022,  0.1615,  0.1280, -0.0770,\n",
            "        -0.2695,  0.3731,  0.0943, -0.4778, -0.1186, -0.0510,  0.2499,  1.0022,\n",
            "         0.2434, -0.1410, -0.0131, -0.0958])\n",
            "our action: [-0.18420123  0.05555595 -0.04901028  0.34219143 -0.3627205   0.006893\n",
            "  0.11291359  0.37515485  0.04591459  0.00577815 -0.36319044  0.37196034\n",
            "  0.16432434 -0.5854032   0.06288584  0.04313637  0.42570102  0.7835129\n",
            " -0.23611683 -0.0364572   0.0759389   0.12955531  0.13511565 -0.04986863\n",
            " -0.24256012  0.40147564  0.06483029 -0.5207033  -0.12850714 -0.04582841\n",
            "  0.26958364  1.0653594   0.25803608 -0.14523321 -0.00561598 -0.1241809 ]\n",
            "real action: tensor([ 0.0325, -0.0313,  0.1816,  0.4586, -0.3340,  0.2333,  0.0761,  0.5944,\n",
            "         2.2486, -0.1844, -0.0096,  0.7941, -0.1909, -0.5088,  0.2855, -0.0344,\n",
            "         0.3837,  0.7780, -0.2408,  0.0705,  0.1564,  1.4385,  2.1604, -0.0641,\n",
            "        -0.1446,  0.7321, -0.2650, -0.3229, -0.1800,  0.1313,  0.3515,  0.8804,\n",
            "         0.1825, -0.4622,  0.1325,  0.9725])\n",
            "our action: [ 0.00704445 -0.06835374  0.19928014  0.49300918 -0.4123596   0.22867525\n",
            "  0.10468464  0.5792347   2.2835162  -0.24241215 -0.04176036  0.8119862\n",
            " -0.09966001 -0.5663906   0.2646469  -0.01167982  0.34930545  0.77224696\n",
            " -0.21860969  0.09795333  0.13555227  1.4073397   2.4320495  -0.06270489\n",
            " -0.11003111  0.7019729  -0.3329155  -0.34360382 -0.19168116  0.13359919\n",
            "  0.35449022  1.1056385   0.22354348 -0.47185647  0.11179602  1.0519872 ]\n",
            "real action: tensor([-2.2653e-01, -5.6730e-02,  1.1095e-02,  4.0466e-01,  2.9881e-01,\n",
            "         2.2262e-01,  4.8154e-02,  3.6970e-01,  1.1894e+00, -4.6656e-03,\n",
            "         7.7391e-02,  4.9004e-01, -1.0314e+00, -5.2048e-01,  4.1927e-02,\n",
            "         7.8548e-02,  3.1550e-01,  2.2092e-01, -1.4158e-03, -2.0334e-01,\n",
            "         3.8296e-03,  5.1925e-01,  1.0757e+00, -4.8783e-02,  1.2351e-01,\n",
            "         5.4460e-01, -8.9018e-01, -1.9802e+00, -1.7898e-01, -1.9782e-01,\n",
            "         5.6223e-01,  1.0169e+00,  1.4060e-01,  2.5310e-01,  1.6352e-01,\n",
            "        -1.0514e+00])\n",
            "our action: [-1.9257466e-01 -6.9142804e-02  3.8912728e-02  3.9953917e-01\n",
            "  2.8136623e-01  2.3778531e-01  4.4877645e-02  3.8497713e-01\n",
            "  1.1278758e+00  3.4590542e-02  7.6108761e-02  4.8874840e-01\n",
            " -9.7063434e-01 -5.3492743e-01  5.7292130e-02  8.7018050e-02\n",
            "  3.2694539e-01  2.4869780e-01 -6.1965734e-04 -2.2080962e-01\n",
            " -1.9173924e-02  5.2301931e-01  9.9481452e-01 -3.5381261e-02\n",
            "  1.1801758e-01  5.2801079e-01 -8.7864792e-01 -1.9475607e+00\n",
            " -1.9130972e-01 -2.1845418e-01  5.1835030e-01  1.0577341e+00\n",
            "  1.2602092e-01  2.3888604e-01  1.9624299e-01 -1.0650530e+00]\n",
            "real action: tensor([-0.4082, -0.0053,  0.0066,  0.4626,  0.5698,  0.2724,  0.0904,  0.4096,\n",
            "         1.2227, -0.0682,  0.0174,  0.4236, -1.7140, -0.9671,  0.0150,  0.0369,\n",
            "         0.2851,  0.7414,  0.0035,  0.0136,  0.2309,  0.6578,  0.1947, -0.0532,\n",
            "         0.1347,  0.4986, -0.6706, -2.1842, -0.1852, -0.1440,  0.5322,  0.7184,\n",
            "         0.0701, -0.0634,  0.2897, -0.3160])\n",
            "our action: [-0.36880046  0.00515401  0.0183269   0.48291105  0.5302529   0.2584867\n",
            "  0.07430832  0.43562552  1.1200505  -0.07559327  0.02373376  0.40228096\n",
            " -1.642118   -0.88942355  0.02899291  0.04490117  0.26478168  0.6822601\n",
            "  0.04150554  0.06114657  0.22588855  0.67578113  0.3197174  -0.07181518\n",
            "  0.10435577  0.50548273 -0.78321826 -1.9704001  -0.18683463 -0.11550414\n",
            "  0.5314024   0.7085978   0.04423614 -0.08162861  0.28180826 -0.25044578]\n",
            "real action: tensor([-0.0750, -0.0257,  0.1263,  0.4627, -0.6530,  0.1609,  0.1687,  0.6083,\n",
            "         2.2364, -0.0688, -0.0836,  0.8035, -0.0057, -0.8334,  0.2841, -0.0125,\n",
            "         0.4059,  0.7303, -0.2666,  0.1037,  0.0981,  1.5960,  2.5610,  0.0253,\n",
            "        -0.1320,  0.7633, -0.5258, -0.6042, -0.1419,  0.1283,  0.3020,  1.0539,\n",
            "         0.3242, -0.3975,  0.0708,  0.7169])\n",
            "our action: [-0.06788482 -0.05269748  0.16430095  0.5166401  -0.58707815  0.16100305\n",
            "  0.18700624  0.6098464   2.2409759  -0.10745379 -0.06792993  0.7942879\n",
            " -0.1148878  -0.67201644  0.25269836  0.02503894  0.3931051   0.8687931\n",
            " -0.22260812  0.13986751  0.04075294  1.5176715   2.4131253  -0.00769806\n",
            " -0.10023602  0.7353301  -0.5496839  -0.46085545 -0.21105209  0.18850575\n",
            "  0.3109316   1.2076197   0.35264838 -0.40552384  0.03232023  0.82150304]\n",
            "real action: tensor([-0.6282, -0.1981,  0.0657,  0.6690, -0.3049,  0.0321,  0.1206,  0.7005,\n",
            "         1.3091,  0.0077, -0.2717,  0.6793, -1.0754, -1.4592, -0.0185,  0.0814,\n",
            "         0.4580,  1.3101, -0.1178,  0.1989,  0.2942,  0.2909,  1.2489,  0.0020,\n",
            "        -0.0319,  0.8069, -0.9828, -1.6555, -0.0659,  0.1500,  0.2282,  1.3353,\n",
            "         0.1843, -0.0846,  0.4964,  0.2748])\n",
            "our action: [-0.5711475  -0.17790633  0.04608493  0.6448639  -0.36255413  0.0224713\n",
            "  0.1442299   0.75101775  1.324439   -0.03388465 -0.328856    0.7419195\n",
            " -0.939365   -1.5325407   0.0257749   0.06117018  0.47750372  1.2804514\n",
            " -0.12121127  0.19655518  0.2816001   0.27176875  1.3470913  -0.00631011\n",
            " -0.06136317  0.75229406 -0.9551571  -1.6624405  -0.04869112  0.10082418\n",
            "  0.25297853  1.2559501   0.22256759 -0.05484806  0.4198745   0.31173956]\n"
          ]
        }
      ],
      "source": [
        "for i in range(80,110):\n",
        "  obs, action  = train_loader.dataset.__getitem__(i)\n",
        "  print(f'real action: {action}')\n",
        "  obs = obs.float().unsqueeze(0).to(device)\n",
        "  if policy.name == 'bco-cnn':\n",
        "    obs = obs.unsqueeze(1)\n",
        "  our_action = policy(obs).squeeze().detach().cpu().numpy()\n",
        "  print(f'our action: {our_action}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "48130645",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 9.82396526e-01  4.79439053e-02 -3.29766128e-01  1.14085569e-01\n",
            "  2.36817154e-01  8.11988831e-02  1.35434379e-01  8.29208982e-03\n",
            "  2.63381942e-01 -2.66817681e-01  1.86539290e-01  2.50136268e-01\n",
            "  2.17640414e-01  7.82742881e-02  1.41631790e-01  9.05683892e-02\n",
            " -2.18686888e-01  2.80836242e-01  1.50088629e-01  2.26539031e-01\n",
            "  2.10000061e-02  1.10441638e-01  6.75695093e-03 -5.96549286e-01\n",
            " -2.76583367e-01 -3.37180025e-01  2.91286171e-01  3.16685388e-01\n",
            "  2.83847125e-01 -4.73767985e-01 -6.22494435e-01 -3.01553190e-01\n",
            " -3.78355010e-01  9.01128626e-02  1.62170801e-03  1.97763178e-01\n",
            " -1.95664289e-01 -6.12505681e-01 -3.12059346e-01 -2.59155353e-01\n",
            "  4.75003078e-02  3.73337600e-02 -1.62453313e-01 -5.33968921e-01\n",
            " -1.49672800e-01  5.13163261e-02 -1.07207912e-01  3.42944809e-01\n",
            "  1.87042694e-01 -2.01743415e-02  5.07439864e-02  2.70421739e-02\n",
            " -1.31430210e-01 -3.04506248e-01  2.34738853e-01  1.02305800e-01\n",
            " -5.80268976e-02  1.16168090e-01  6.30838677e-02 -2.33515969e-01\n",
            " -2.91447493e-01  2.34738853e-01  1.02305800e-01 -5.80268976e-02\n",
            "  1.16168090e-01 -9.17286755e-01 -6.57661741e-01 -4.95195001e-02\n",
            "  2.82923178e-01  2.31581464e-01 -5.08298585e-01 -5.30780165e-01\n",
            " -9.20306433e-01 -7.07370217e-01 -1.41389754e-01  4.36602193e-02\n",
            "  5.12485683e-02 -2.81106905e-01  1.05816866e-01 -8.88183701e-01\n",
            " -7.00214590e-01 -2.43809980e-01  1.00337257e-01 -3.33035178e-01\n",
            "  5.88541931e-02 -6.41411259e-02 -1.62566659e-01  7.48147403e-02\n",
            "  5.15707456e-02  5.10510992e-01 -3.11761042e-01  8.11888335e-02\n",
            "  1.18457146e-01 -4.91835194e-02 -1.92285236e-02  3.10112764e-02\n",
            "  4.08318653e-01 -1.36598690e-01  1.14364557e-01  2.91112357e-01\n",
            " -1.11281315e-02 -1.90019232e-01  4.88103913e-03  4.08318653e-01\n",
            " -1.36598690e-01  1.14364557e-01  2.91112357e-01 -1.41349601e-01\n",
            "  3.70406687e-02  1.16884433e-01  8.44645332e-02 -1.16504862e+00\n",
            "  2.30535975e-01 -4.50229562e-01  1.31853500e-01  2.21044316e-01\n",
            "  1.86688896e-01 -1.50823881e+00  3.34400086e-01 -4.30807347e-01\n",
            "  2.06403983e-01  1.00155937e-01  5.11726925e-01  1.21248366e+00\n",
            "  5.14197147e-01 -5.22653577e-01  6.97345106e-02  1.61509001e-01\n",
            " -3.15601281e-02 -2.60084608e-01 -2.55296880e-01 -9.36682995e-01\n",
            "  7.38845277e-02  7.46861326e-02 -1.45981148e-02 -1.45555517e-01\n",
            " -3.26099548e-01 -1.55855510e+00  9.07513322e-02  1.18656193e-01\n",
            " -1.11431440e-01 -6.99753691e-01 -3.02020151e-01 -1.42796618e+00\n",
            "  1.99163603e-01 -1.02479395e-01  4.31429215e-01 -2.72844950e+00\n",
            "  8.54402956e-02 -1.04830876e+00  6.79505570e-03  1.20713698e-01\n",
            "  7.23093254e-01 -2.26055982e+00 -5.32144088e-01 -9.92350555e-01\n",
            " -7.85915399e-02  2.78711035e-01  7.23093254e-01 -2.26055982e+00\n",
            " -5.32144088e-01 -3.63162438e-01  3.66106422e-02  1.23786334e-02\n",
            "  5.64343181e-01 -1.18739143e+00 -2.76511872e-01 -5.10881880e-01\n",
            " -2.15072148e-02 -3.37102514e-01  2.74394707e-01 -9.51496559e-01\n",
            "  3.62894356e-01 -3.97502614e-01  4.40214324e-02 -4.18625862e-01\n",
            " -2.96055268e-02 -1.01836754e+00  2.75786659e-01 -4.05215391e-01\n",
            "  1.18582419e-01 -4.51205567e-01  2.94501128e-01  6.19932836e-01\n",
            "  8.90374833e-02 -2.99695489e-01  7.64671863e-02 -6.81908955e-01\n",
            "  2.82107626e-01  5.92452146e-01  1.13970037e-01 -2.22807962e-01\n",
            "  7.55357816e-02 -6.77365607e-01  2.82107626e-01  5.92452146e-01\n",
            "  1.13970037e-01]\n",
            "tensor([[0.2867, 0.2597, 0.2487, 0.2616, 0.2651, 0.2606, 0.2622, 0.2585, 0.2659,\n",
            "         0.2505, 0.2637, 0.2655, 0.2646, 0.2605, 0.2624, 0.2609, 0.2519, 0.2664,\n",
            "         0.2626, 0.2648, 0.2589, 0.2615, 0.2585, 0.2410, 0.2503, 0.2485, 0.2667,\n",
            "         0.2674, 0.2665, 0.2446, 0.2402, 0.2495, 0.2473, 0.2609, 0.2583, 0.2640,\n",
            "         0.2526, 0.2405, 0.2492, 0.2508, 0.2596, 0.2594, 0.2536, 0.2428, 0.2539,\n",
            "         0.2598, 0.2552, 0.2682, 0.2637, 0.2577, 0.2597, 0.2591, 0.2545, 0.2495,\n",
            "         0.2651, 0.2612, 0.2566, 0.2616, 0.2601, 0.2515, 0.2498, 0.2651, 0.2612,\n",
            "         0.2566, 0.2616, 0.2317, 0.2392, 0.2568, 0.2665, 0.2650, 0.2436, 0.2429,\n",
            "         0.2316, 0.2378, 0.2542, 0.2595, 0.2598, 0.2501, 0.2613, 0.2325, 0.2380,\n",
            "         0.2512, 0.2612, 0.2486, 0.2600, 0.2564, 0.2536, 0.2604, 0.2598, 0.2731,\n",
            "         0.2492, 0.2606, 0.2617, 0.2568, 0.2577, 0.2592, 0.2701, 0.2543, 0.2616,\n",
            "         0.2667, 0.2579, 0.2528, 0.2584, 0.2701, 0.2543, 0.2616, 0.2667, 0.2542,\n",
            "         0.2593, 0.2617, 0.2607, 0.2245, 0.2649, 0.2452, 0.2621, 0.2647, 0.2637,\n",
            "         0.2146, 0.2680, 0.2458, 0.2643, 0.2612, 0.2731, 0.2934, 0.2732, 0.2431,\n",
            "         0.2603, 0.2630, 0.2574, 0.2507, 0.2509, 0.2311, 0.2604, 0.2604, 0.2578,\n",
            "         0.2541, 0.2488, 0.2131, 0.2609, 0.2617, 0.2550, 0.2380, 0.2495, 0.2169,\n",
            "         0.2640, 0.2553, 0.2708, 0.1792, 0.2607, 0.2279, 0.2585, 0.2618, 0.2792,\n",
            "         0.1928, 0.2429, 0.2295, 0.2560, 0.2663, 0.2792, 0.1928, 0.2429, 0.2478,\n",
            "         0.2593, 0.2586, 0.2746, 0.2239, 0.2503, 0.2435, 0.2576, 0.2485, 0.2662,\n",
            "         0.2307, 0.2688, 0.2468, 0.2595, 0.2461, 0.2574, 0.2288, 0.2663, 0.2465,\n",
            "         0.2617, 0.2452, 0.2668, 0.2762, 0.2609, 0.2496, 0.2605, 0.2385, 0.2664,\n",
            "         0.2754, 0.2616, 0.2518, 0.2605, 0.2387, 0.2664, 0.2754]])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_19870/4091109280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;31m# print(f'our action: {our_action}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Francesco/rl_project/acrobatic-agents/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Francesco/rl_project/acrobatic-agents/models/bco_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Francesco/rl_project/acrobatic-agents/.venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Francesco/rl_project/acrobatic-agents/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/Francesco/rl_project/acrobatic-agents/.venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    309\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 310\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper___slow_conv2d_forward)"
          ]
        }
      ],
      "source": [
        "# not normalized observations / manual normalization\n",
        "stop_at = 5\n",
        "policy.eval()\n",
        "for obs in expert_observations:\n",
        "  print(obs)\n",
        "  inputs = torch.from_numpy(obs[:196]).float().unsqueeze(0)\n",
        "  inputs = 2 * ((inputs - min_val) / (max_val - min_val)) - 1\n",
        "  print(inputs)\n",
        "  output = policy(inputs).squeeze().detach().cpu().numpy()\n",
        "  # print(f'our action: {our_action}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe6d5f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalized observations\n",
        "for i in range(80,110):\n",
        "  obs = train_loader.dataset.__getitem__(i)[0]\n",
        "  obs = obs.float().unsqueeze(0).to(device)\n",
        "  print(obs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75da1acc",
      "metadata": {},
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "82745485",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "\n",
        "# save_parameters()\n",
        "version = 3\n",
        "policy.save_parameters(root_dir+'/checkpoints/', version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc5191c",
      "metadata": {},
      "source": [
        "## Loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "57b3ac73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model Behavioral-Cloning-Agent state parameters\n",
            "From :/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/checkpoints/behavioral-cloning-agent.pt\n",
            "/home/bitfra/Desktop/Francesco/rl_project/acrobatic-agents/checkpoints/behavioral-cloning-agent.pt\n"
          ]
        }
      ],
      "source": [
        "src = root_dir+'/checkpoints/'+policy.name.lower()+'.pt'\n",
        "policy.load_parameters(src)\n",
        "print(root_dir+'/checkpoints/'+policy.name.lower()+'.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692b400b",
      "metadata": {},
      "source": [
        "# BCO CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f8751c4",
      "metadata": {},
      "source": [
        "## Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c99a49e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "\n",
        "class ExpertDataSetCNN(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = torch.from_numpy(expert_observations).float()\n",
        "        self.actions = self.__preprocess__(torch.from_numpy(expert_actions))\n",
        "        \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.observations[index], self.actions[index])\n",
        "        # normalized_observations = 2 * ((self.observations[idx] - self.observations.min()) / (self.observations.max() - self.observations.min())) - 1\n",
        "        # normalized_actions = 2 * ((self.actions[idx] - self.actions.min()) / (self.actions.max() - self.actions.min())) - 1\n",
        "        # normalized_data = (normalized_observations, self.actions[idx])\n",
        "        normalized_data = (self.observations[idx], self.actions[idx])\n",
        "        return normalized_data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "    \n",
        "    \n",
        "    def __preprocess__(self, data, clip_value=1e38):\n",
        "        # Clip values to a maximum and minimum range\n",
        "        data = torch.clamp(data, min=-clip_value, max=clip_value)\n",
        "        \n",
        "        # Convert to float\n",
        "        return data.float()\n",
        "    \n",
        "    def __min__max__(self):\n",
        "        return self.observations.min(), self.observations.max() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "418019d8",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d59f77",
      "metadata": {},
      "outputs": [],
      "source": [
        "###### Define student agent\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "from os.path import join, exists\n",
        "from os import mkdir, remove, rename\n",
        "# from os import mkdir, unlink, listdir, getpid, remove\n",
        "\n",
        "\n",
        "class BCOAgentCNN(nn.Module):\n",
        "\n",
        "  def __init__(self, obs_space, \n",
        "               action_space,\n",
        "               h_size=16,\n",
        "               device='cpu'\n",
        "              ) -> None:\n",
        "    \n",
        "    super(BCOAgentCNN, self).__init__()\n",
        "\n",
        "    self.name = 'bco-fc'\n",
        "    self.device = device\n",
        "\n",
        "    self.n_inputs = obs_space\n",
        "    self.n_outputs = action_space\n",
        "\n",
        "    # Policy Network\n",
        "    self.fc1 = nn.Linear(self.n_inputs, h_size) #16\n",
        "    self.bn1 = nn.BatchNorm1d(h_size) #16\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(h_size, self.n_outputs) #16\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "  \n",
        "  def load_parameters(self, src, version):\n",
        "    src = src+self.name.lower()+'-'+str(version)+'.pt'\n",
        "    if exists(src):\n",
        "        print(\"Loading model \"+self.name.lower()+'-'+str(version)+\" state parameters\")\n",
        "        print(\"From :{}\".format(src))\n",
        "        self.load_state_dict(torch.load(src, map_location=self.device))\n",
        "        return self\n",
        "    else:\n",
        "        print(\"Error no model \"+self.name.lower()+'-'+str(version)+'.pt'+\" found!\")\n",
        "        exit(1)\n",
        "\n",
        "  \n",
        "  def save_parameters(self, dest, version):\n",
        "    save_name = self.name.lower()+'-'+str(version)+'.pt'\n",
        "\n",
        "    if not exists(dest): \n",
        "      mkdir(dest)\n",
        "    else: \n",
        "        if exists(dest+save_name):\n",
        "          rename(dest+save_name, dest+save_name+'.bk')\n",
        "\n",
        "    torch.save(self.state_dict(), dest+save_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0742b17d",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc1a206",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5968344",
      "metadata": {},
      "source": [
        "## Saving"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
