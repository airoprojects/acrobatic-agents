{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b09a0b12",
      "metadata": {
        "id": "b09a0b12"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from os.path import join, exists\n",
        "from os import mkdir, unlink, listdir, getpid, remove\n",
        "#from .autonotebook import tqdm as notebook_tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from statistics import mean\n",
        "import math\n",
        "from torch.optim import lr_scheduler\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83adcf6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ce03945f",
      "metadata": {
        "id": "ce03945f"
      },
      "outputs": [],
      "source": [
        "##dataset class\n",
        "from torch.utils.data.dataset import Dataset, random_split\n",
        "\n",
        "class ExpertDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = torch.from_numpy(expert_observations)\n",
        "        self.actions = self.preprocess_data(torch.from_numpy(expert_actions))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.observations[index], self.actions[index])\n",
        "        normalized_observations = 2 * ((self.observations[idx] - self.observations.min()) / (self.observations.max() - self.observations.min())) - 1\n",
        "        # normalized_actions = 2 * ((self.actions[idx] - self.actions.min()) / (self.actions.max() - self.actions.min())) - 1\n",
        "        normalized_data = (normalized_observations, self.actions[idx])\n",
        "        return normalized_data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "    \n",
        "    def preprocess_data(self, data, clip_value=1e38):\n",
        "        # Clip values to a maximum and minimum range\n",
        "        data = torch.clamp(data, min=-clip_value, max=clip_value)\n",
        "        \n",
        "        # Convert to float\n",
        "        return data.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "11af5407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11af5407",
        "outputId": "bc497a92-1701-4426-c1cd-4fb74f7545cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert actions len: 8000\n",
            "Expert observations len: 8000\n",
            "Discarded data\n",
            "Discarded form np: 0\n",
            "Discarded form torch: 0\n",
            "Shapes:\n",
            "torch.Size([36])\n",
            "torch.Size([196])\n"
          ]
        }
      ],
      "source": [
        "expert_observations = np.load('./data/expert-observations.npy', allow_pickle=True)\n",
        "expert_actions = np.load('./data/expert-actions.npy', allow_pickle=True)\n",
        "\n",
        "count_discarded_numpy = 0\n",
        "count_discarded = 0\n",
        "\n",
        "\n",
        "new_exp_action = expert_actions\n",
        "\n",
        "list_of_index_to_drop = []\n",
        "for i, a in enumerate(expert_actions):\n",
        "  if (a > 1e2).any() or (a > 1e2).any():\n",
        "  # if not np.isfinite(a).all(): \n",
        "    list_of_index_to_drop.append(i)\n",
        "    print(i)\n",
        "    print(a)\n",
        "    count_discarded_numpy+=1\n",
        "    # break\n",
        "\n",
        "\n",
        "print(\"Expert actions len: {}\".format(len(expert_actions)))\n",
        "print(\"Expert observations len: {}\".format(len(expert_observations)))\n",
        "\n",
        "expert_dataset = ExpertDataSet(expert_observations, expert_actions)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(expert_dataset)):\n",
        "  a = expert_dataset.__getitem__(i)[1]\n",
        "  # print(a.max())\n",
        "  # print(a.min())\n",
        "  if (a > 1e2).any() or (a < -1e2).any() :\n",
        "  # if not torch.isfinite(a).any():\n",
        "    count_discarded += 1\n",
        "    print(a)\n",
        "\n",
        "\n",
        "print(\"Discarded data\")\n",
        "print(\"Discarded form np: {}\".format(count_discarded_numpy))\n",
        "print(\"Discarded form torch: {}\".format(count_discarded))\n",
        "\n",
        "#split in 80% training and 20%test\n",
        "batch_size = 64\n",
        "train_prop = 0.8\n",
        "train_size = int(train_prop * len(expert_dataset))\n",
        "test_size = len(expert_dataset) - train_size\n",
        "train_expert_dataset, test_expert_dataset = random_split(expert_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(  dataset=train_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(  dataset=test_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(train_loader.dataset.__getitem__(0)[1].shape)\n",
        "print(train_loader.dataset.__getitem__(0)[0].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "94873ce1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Policy agent\n",
        "\n",
        "class BCAgent(nn.Module):\n",
        "\n",
        "  def __init__(self, obs_space, action_space) -> None:\n",
        "    self.name = 'Behavioral-Cloning-Agent'\n",
        "\n",
        "    super(BCAgent, self).__init__()\n",
        "\n",
        "    self.n_inputs = obs_space\n",
        "    self.n_outputs = action_space\n",
        "\n",
        "    # Policy Network\n",
        "    self.fc1 = nn.Linear(self.n_inputs,16)\n",
        "    self.bn1 = nn.BatchNorm1d(16)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(16, self.n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "  \n",
        "  def load_parameters(self, dir): \n",
        "    if exists(dir+self.name.lower()+'.pt'):\n",
        "        print(\"Loading model \"+self.name+\" state parameters\")\n",
        "        self.load_state_dict(torch.load(dir+self.name.lower()+'.pt', map_location=self.device))\n",
        "        return self\n",
        "    else:\n",
        "        print(\"Error no model \"+self.name.lower()+\" found!\")\n",
        "        exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "09e78876",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train functions\n",
        "\n",
        "def train(\n",
        "        policy,\n",
        "        train_epochs,\n",
        "        eval_epochs,\n",
        "        train_loader, \n",
        "        test_loader,\n",
        "        optimizer,\n",
        "        loss_criterion,\n",
        "        scheduler,\n",
        "        trashold\n",
        "    ):\n",
        "\n",
        "    policy.train()\n",
        "    policy.to(device)\n",
        "    \n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    unused_val = 0\n",
        "\n",
        "    \n",
        "\n",
        "    for epoch in range(train_epochs):\n",
        "     \n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "            obs, expert_action = data.to(device), target.to(device)\n",
        "            obs = obs.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            student_action = policy(obs)\n",
        "            expert_action = expert_action.float()\n",
        "\n",
        "            loss = loss_criterion(student_action, expert_action)\n",
        "            # loss.register_hook(lambda grad: print(grad))\n",
        "            loss.backward()\n",
        "            # print(\"Loss: {}\".format(loss.item()))\n",
        "            \n",
        "            \n",
        "         \n",
        "            if not loss.item() == torch.inf: \n",
        "                epoch_loss += loss.item()\n",
        "                optimizer.step()\n",
        "                \n",
        "\n",
        "            else:\n",
        "                unused_val += 1\n",
        "                # print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                # print(f'obs -> {obs}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                print(f'expert_action -> {expert_action}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                print(f'student_action -> {student_action}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                return expert_action,student_action\n",
        "\n",
        "            # res = print_gradients()\n",
        "            \n",
        "            # print(\"###############################################################################\\n\")\n",
        "\n",
        "            if torch.isnan(student_action).any(): \n",
        "                print('e successo')\n",
        "                break\n",
        "            # if res == 1: \n",
        "            #     print(\"\\n______________________________________________________________________________\")\n",
        "            #     print(student_action.shape)\n",
        "            #     for i, ea in enumerate(expert_action):\n",
        "            #         if not np.isfinite(ea).all():\n",
        "            #             print(i+64)\n",
        "            #             print(f'expert_action -> {ea}')\n",
        "\n",
        "            #     print(\"\\n______________________________________________________________________________\")\n",
        "            #     print(f'Max expert_action -> {expert_action.max()}')\n",
        "            #     print(f'Min expert_action -> {expert_action.min()}')\n",
        "            #     print(f'Max student_action -> {student_action.max()}')\n",
        "            #     print(f'Min student_action -> {student_action.min()}')\n",
        "            #     break\n",
        "            \n",
        "            # print(\"Student actions: {}\".format(student_action.shape))\n",
        "            # print(\"Expert actions: {}\".format(expert_action.shape))\n",
        "        if epoch%50==0 and epoch < trashold :\n",
        "            scheduler.step()\n",
        "        \n",
        "        \n",
        "        # compute accuracy\n",
        "        print(\"Epoch {}\".format(epoch))\n",
        "        print(\"Train Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "        validation(test_loader,policy,loss_criterion,num_epochs=eval_epochs)\n",
        "        print(\"Unused Loss: {}\".format(unused_val))\n",
        "        epoch_loss = 0\n",
        "        unused_val = 0\n",
        "        print(\"###############################################################################\\n\")\n",
        "\n",
        "\n",
        "def validation(loader, policy,loss_criterion, num_epochs):\n",
        "    policy.eval()\n",
        "    epoch_loss = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            obs, expert_action = data.to(device), target.to(device)\n",
        "            obs = obs.float()\n",
        "            student_action = policy(obs)\n",
        "            loss = loss_criterion(student_action, expert_action)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    print(\"Validation Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "\n",
        "def print_gradients(self):\n",
        "    for name, param in self.policy.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if torch.isnan(param.grad).any(): \n",
        "                return 1#break\n",
        "            # print(f\"Gradient of {name}: {param.grad}\")\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1d8a59c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train Loss: 0.031098525011911987\n",
            "Validation Loss: 0.08377772159874439\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 1\n",
            "Train Loss: 0.014836137283127755\n",
            "Validation Loss: 0.04022401764988899\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 0.007124578395159915\n",
            "Validation Loss: 0.03298129336442798\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 0.005983646113891155\n",
            "Validation Loss: 0.02942033389117569\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 0.005324596650898457\n",
            "Validation Loss: 0.025375813227146864\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 0.0047171716613229366\n",
            "Validation Loss: 0.024548846906982363\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 0.004290212591295131\n",
            "Validation Loss: 0.023331775334663688\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 0.003944714197423309\n",
            "Validation Loss: 0.019508287066128106\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 0.0034879350778646767\n",
            "Validation Loss: 0.017496783202514053\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 0.0034036337479483336\n",
            "Validation Loss: 0.018359668737175525\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 0.0035962895961711185\n",
            "Validation Loss: 0.017048813108121976\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 0.0034046675794525074\n",
            "Validation Loss: 0.018799302654806525\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 0.0030957524495897814\n",
            "Validation Loss: 0.015860541535075753\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 0.0029723097820533438\n",
            "Validation Loss: 0.018764163148589433\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 0.003549263479653746\n",
            "Validation Loss: 0.016815770014654844\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 0.0029015950090251863\n",
            "Validation Loss: 0.015797496156301348\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 0.0031968014244921506\n",
            "Validation Loss: 0.016596515463897957\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 0.0031948889666819015\n",
            "Validation Loss: 0.015749947511358185\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 0.0026869359891861675\n",
            "Validation Loss: 0.013628988882992417\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 0.0027317255808156915\n",
            "Validation Loss: 0.018631786906626077\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 0.0028909964641206896\n",
            "Validation Loss: 0.014665425979765133\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 0.0025879768331651576\n",
            "Validation Loss: 0.015292997618671507\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 0.002653687292477116\n",
            "Validation Loss: 0.013928718015667982\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 0.0025962016414268875\n",
            "Validation Loss: 0.012952853710157797\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 0.0025571985478745774\n",
            "Validation Loss: 0.014120678212493657\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 0.0024607948993798346\n",
            "Validation Loss: 0.014166571272071452\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 26\n",
            "Train Loss: 0.0026123606890905648\n",
            "Validation Loss: 0.015500034700380638\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 27\n",
            "Train Loss: 0.0027771366023807784\n",
            "Validation Loss: 0.01544089803704992\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 28\n",
            "Train Loss: 0.0027454246528213844\n",
            "Validation Loss: 0.013854947593063115\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 29\n",
            "Train Loss: 0.0024721044063335286\n",
            "Validation Loss: 0.013120381396729499\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 30\n",
            "Train Loss: 0.0027210632103378883\n",
            "Validation Loss: 0.013527382351458072\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 31\n",
            "Train Loss: 0.0026533420057967307\n",
            "Validation Loss: 0.016192717088852077\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 32\n",
            "Train Loss: 0.0026496156299253924\n",
            "Validation Loss: 0.013482833451707848\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 33\n",
            "Train Loss: 0.0023827570222783832\n",
            "Validation Loss: 0.014468100960366428\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 34\n",
            "Train Loss: 0.0024172534819808787\n",
            "Validation Loss: 0.014338399991393089\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 35\n",
            "Train Loss: 0.002590652728686109\n",
            "Validation Loss: 0.013289434174075722\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 36\n",
            "Train Loss: 0.0023398190370062365\n",
            "Validation Loss: 0.012965374619816429\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 37\n",
            "Train Loss: 0.002452914345776662\n",
            "Validation Loss: 0.013679860396077857\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 38\n",
            "Train Loss: 0.00239170094311703\n",
            "Validation Loss: 0.01275065035559237\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 39\n",
            "Train Loss: 0.002380584395141341\n",
            "Validation Loss: 0.013061162593076006\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 40\n",
            "Train Loss: 0.0025429606286343186\n",
            "Validation Loss: 0.012828587103285827\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 41\n",
            "Train Loss: 0.002427158739301376\n",
            "Validation Loss: 0.012396616511978209\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 42\n",
            "Train Loss: 0.002336145041626878\n",
            "Validation Loss: 0.012572132817003876\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 43\n",
            "Train Loss: 0.0026744182663969696\n",
            "Validation Loss: 0.012362070030067117\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 44\n",
            "Train Loss: 0.002387702104169875\n",
            "Validation Loss: 0.013305546679766848\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 45\n",
            "Train Loss: 0.0025531882379436865\n",
            "Validation Loss: 0.012979029784910381\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 46\n",
            "Train Loss: 0.002516676236409694\n",
            "Validation Loss: 0.013653297063428908\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 47\n",
            "Train Loss: 0.002711255367612466\n",
            "Validation Loss: 0.01414201308740303\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 48\n",
            "Train Loss: 0.0029536567654577083\n",
            "Validation Loss: 0.013599644221831114\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 49\n",
            "Train Loss: 0.0022851268184604125\n",
            "Validation Loss: 0.01236579316901043\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 50\n",
            "Train Loss: 0.0022076805561664515\n",
            "Validation Loss: 0.012549103194469353\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 51\n",
            "Train Loss: 0.0022671888646436855\n",
            "Validation Loss: 0.012758534256136045\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 52\n",
            "Train Loss: 0.002397345299832523\n",
            "Validation Loss: 0.012648659842088818\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 53\n",
            "Train Loss: 0.0022916035512753298\n",
            "Validation Loss: 0.013825643921736628\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 54\n",
            "Train Loss: 0.002388160826812964\n",
            "Validation Loss: 0.01157180341775529\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 55\n",
            "Train Loss: 0.0023159195850894322\n",
            "Validation Loss: 0.012545488086761907\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 56\n",
            "Train Loss: 0.002392057726974599\n",
            "Validation Loss: 0.014544805805198848\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 57\n",
            "Train Loss: 0.002237334839301184\n",
            "Validation Loss: 0.01110429625143297\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 58\n",
            "Train Loss: 0.0022218882049492095\n",
            "Validation Loss: 0.013528064633719623\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 59\n",
            "Train Loss: 0.0025242228351999075\n",
            "Validation Loss: 0.014100017653545365\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 60\n",
            "Train Loss: 0.0024496840513893404\n",
            "Validation Loss: 0.01489223396172747\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 61\n",
            "Train Loss: 0.0023670751927420495\n",
            "Validation Loss: 0.013637309577316046\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 62\n",
            "Train Loss: 0.0023406712555151896\n",
            "Validation Loss: 0.012783279593568295\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 63\n",
            "Train Loss: 0.0021392639019177295\n",
            "Validation Loss: 0.011962083046673797\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 64\n",
            "Train Loss: 0.002192371641576756\n",
            "Validation Loss: 0.012263837214559316\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 65\n",
            "Train Loss: 0.0023335275985300542\n",
            "Validation Loss: 0.011606215356150642\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 66\n",
            "Train Loss: 0.0022780533344484866\n",
            "Validation Loss: 0.012894254233688117\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 67\n",
            "Train Loss: 0.0023246482976537666\n",
            "Validation Loss: 0.01265234523336403\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 68\n",
            "Train Loss: 0.002220377554767765\n",
            "Validation Loss: 0.011978306071250699\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 69\n",
            "Train Loss: 0.003001135974773206\n",
            "Validation Loss: 0.02642821236979216\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 70\n",
            "Train Loss: 0.0028524732784717343\n",
            "Validation Loss: 0.012789261719444767\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 71\n",
            "Train Loss: 0.0022702574760478456\n",
            "Validation Loss: 0.01268578099028673\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 72\n",
            "Train Loss: 0.00217573795147473\n",
            "Validation Loss: 0.012137251818203368\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 73\n",
            "Train Loss: 0.002501205262960866\n",
            "Validation Loss: 0.013464239440509118\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 74\n",
            "Train Loss: 0.002492814836441539\n",
            "Validation Loss: 0.012219529213616624\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 75\n",
            "Train Loss: 0.00209189426881494\n",
            "Validation Loss: 0.012820959206437691\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 76\n",
            "Train Loss: 0.002172710095474031\n",
            "Validation Loss: 0.0131717909371946\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 77\n",
            "Train Loss: 0.0022543680848320946\n",
            "Validation Loss: 0.011135820223717018\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 78\n",
            "Train Loss: 0.0020915602217428386\n",
            "Validation Loss: 0.011686004172079266\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 79\n",
            "Train Loss: 0.0024795274253119714\n",
            "Validation Loss: 0.012716192910447717\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 80\n",
            "Train Loss: 0.0024190489784814417\n",
            "Validation Loss: 0.012769636115990579\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 81\n",
            "Train Loss: 0.0022839662899059475\n",
            "Validation Loss: 0.010676732937572524\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 82\n",
            "Train Loss: 0.002134709117526654\n",
            "Validation Loss: 0.010724417842138791\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 83\n",
            "Train Loss: 0.0024925621395232157\n",
            "Validation Loss: 0.013408051314763724\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 84\n",
            "Train Loss: 0.00213301008741837\n",
            "Validation Loss: 0.010608061284292489\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 85\n",
            "Train Loss: 0.0020329997438238933\n",
            "Validation Loss: 0.01106455887435004\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 86\n",
            "Train Loss: 0.0021443689169245773\n",
            "Validation Loss: 0.012174956785747782\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 87\n",
            "Train Loss: 0.0021008205154794267\n",
            "Validation Loss: 0.010677359779947437\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 88\n",
            "Train Loss: 0.002044585843104869\n",
            "Validation Loss: 0.011900640074745752\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 89\n",
            "Train Loss: 0.002225388442748226\n",
            "Validation Loss: 0.011566121127107181\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 90\n",
            "Train Loss: 0.0021385498724703213\n",
            "Validation Loss: 0.012302854568697513\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 91\n",
            "Train Loss: 0.0022657718177651986\n",
            "Validation Loss: 0.012160521212499588\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 92\n",
            "Train Loss: 0.002288133299007313\n",
            "Validation Loss: 0.013796309605240822\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 93\n",
            "Train Loss: 0.0022755292707006447\n",
            "Validation Loss: 0.01279033700178843\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 94\n",
            "Train Loss: 0.00215830006665783\n",
            "Validation Loss: 0.011772816545562819\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 95\n",
            "Train Loss: 0.00210650812878157\n",
            "Validation Loss: 0.012049614468123764\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 96\n",
            "Train Loss: 0.002122202099126298\n",
            "Validation Loss: 0.011589141609147192\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 97\n",
            "Train Loss: 0.0024919455402414316\n",
            "Validation Loss: 0.013457890196004883\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 98\n",
            "Train Loss: 0.002312978600966744\n",
            "Validation Loss: 0.010899374758591875\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 99\n",
            "Train Loss: 0.0021201437967829405\n",
            "Validation Loss: 0.011758617664454504\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 100\n",
            "Train Loss: 0.002310814877564553\n",
            "Validation Loss: 0.012185042353812604\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 101\n",
            "Train Loss: 0.0021429631987120957\n",
            "Validation Loss: 0.01052378319320269\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 102\n",
            "Train Loss: 0.0024739006895106285\n",
            "Validation Loss: 0.012482325930614024\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 103\n",
            "Train Loss: 0.0021964841303997672\n",
            "Validation Loss: 0.010980199859477579\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 104\n",
            "Train Loss: 0.002039747879025526\n",
            "Validation Loss: 0.011482146159978583\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 105\n",
            "Train Loss: 0.0020113082506577483\n",
            "Validation Loss: 0.011417408577981404\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 106\n",
            "Train Loss: 0.002143656715779798\n",
            "Validation Loss: 0.011821446159738116\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 107\n",
            "Train Loss: 0.0021585984621196987\n",
            "Validation Loss: 0.011726762608159334\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 108\n",
            "Train Loss: 0.002415355160483159\n",
            "Validation Loss: 0.01436954588338267\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 109\n",
            "Train Loss: 0.0030291623828088633\n",
            "Validation Loss: 0.017790943132713437\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 110\n",
            "Train Loss: 0.0028182766202371565\n",
            "Validation Loss: 0.013152086122427136\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 111\n",
            "Train Loss: 0.0023730523462290876\n",
            "Validation Loss: 0.012605066527612507\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 112\n",
            "Train Loss: 0.0023337717732647436\n",
            "Validation Loss: 0.011876728556235321\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 113\n",
            "Train Loss: 0.002381951228308026\n",
            "Validation Loss: 0.012178037764970213\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 114\n",
            "Train Loss: 0.0022431447095004843\n",
            "Validation Loss: 0.012161685345927254\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 115\n",
            "Train Loss: 0.002288573845871724\n",
            "Validation Loss: 0.012698442799737676\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 116\n",
            "Train Loss: 0.0022024698031600566\n",
            "Validation Loss: 0.013137713492615149\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 117\n",
            "Train Loss: 0.002797910341178067\n",
            "Validation Loss: 0.013353128946037032\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 118\n",
            "Train Loss: 0.002265157504589297\n",
            "Validation Loss: 0.012212403025478125\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 119\n",
            "Train Loss: 0.002291159032320138\n",
            "Validation Loss: 0.01239132055779919\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 120\n",
            "Train Loss: 0.0023118370486190543\n",
            "Validation Loss: 0.011907531023025513\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 121\n",
            "Train Loss: 0.0023137134267017245\n",
            "Validation Loss: 0.011619155482039787\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 122\n",
            "Train Loss: 0.002178776405053213\n",
            "Validation Loss: 0.01182010735559743\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 123\n",
            "Train Loss: 0.0023510771538713016\n",
            "Validation Loss: 0.015166546386899427\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 124\n",
            "Train Loss: 0.0027254981716396285\n",
            "Validation Loss: 0.015334530166583135\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 125\n",
            "Train Loss: 0.0026172469975426793\n",
            "Validation Loss: 0.012650128966197372\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 126\n",
            "Train Loss: 0.0022261440914007834\n",
            "Validation Loss: 0.013497190542984754\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 127\n",
            "Train Loss: 0.002441686850215774\n",
            "Validation Loss: 0.01154741479898803\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 128\n",
            "Train Loss: 0.002273345655121375\n",
            "Validation Loss: 0.013309391080401838\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 129\n",
            "Train Loss: 0.002281613631057553\n",
            "Validation Loss: 0.01318318818579428\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 130\n",
            "Train Loss: 0.0023901580274105073\n",
            "Validation Loss: 0.013488318679155781\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 131\n",
            "Train Loss: 0.002251017788075842\n",
            "Validation Loss: 0.012826970536261797\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 132\n",
            "Train Loss: 0.0022910960845183583\n",
            "Validation Loss: 0.011824808333767579\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 133\n",
            "Train Loss: 0.002280020659964066\n",
            "Validation Loss: 0.012858776843640953\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 134\n",
            "Train Loss: 0.0025153570901602505\n",
            "Validation Loss: 0.01190596778644249\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 135\n",
            "Train Loss: 0.0023594864789629353\n",
            "Validation Loss: 0.012106935942429118\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 136\n",
            "Train Loss: 0.0022832693959935566\n",
            "Validation Loss: 0.016942138094455005\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 137\n",
            "Train Loss: 0.0024034215114079414\n",
            "Validation Loss: 0.013575104022456798\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 138\n",
            "Train Loss: 0.002486690162040759\n",
            "Validation Loss: 0.012772574936971069\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 139\n",
            "Train Loss: 0.002344261716643814\n",
            "Validation Loss: 0.011314346650615335\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 140\n",
            "Train Loss: 0.0024188701855018735\n",
            "Validation Loss: 0.014674455157946796\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 141\n",
            "Train Loss: 0.0026043086347635833\n",
            "Validation Loss: 0.012526363870128988\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 142\n",
            "Train Loss: 0.002247028927667998\n",
            "Validation Loss: 0.011415042720036581\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 143\n",
            "Train Loss: 0.002160007064594538\n",
            "Validation Loss: 0.011584976037265732\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 144\n",
            "Train Loss: 0.0021295236301375553\n",
            "Validation Loss: 0.013230906514218077\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 145\n",
            "Train Loss: 0.0026896990049863232\n",
            "Validation Loss: 0.013642605885397643\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 146\n",
            "Train Loss: 0.002249112846329808\n",
            "Validation Loss: 0.013157729353988543\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 147\n",
            "Train Loss: 0.0021729155466891827\n",
            "Validation Loss: 0.013778798778075725\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 148\n",
            "Train Loss: 0.0022545003367122262\n",
            "Validation Loss: 0.011696074592182413\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 149\n",
            "Train Loss: 0.0021279488448635673\n",
            "Validation Loss: 0.010954357071896084\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 150\n",
            "Train Loss: 0.002055610549869016\n",
            "Validation Loss: 0.010659438353031873\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 151\n",
            "Train Loss: 0.0021826578871696257\n",
            "Validation Loss: 0.01298140962375328\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 152\n",
            "Train Loss: 0.0025480625173076987\n",
            "Validation Loss: 0.011632315906317671\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 153\n",
            "Train Loss: 0.0021383066050475463\n",
            "Validation Loss: 0.011481197316898032\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 154\n",
            "Train Loss: 0.0024314469689852556\n",
            "Validation Loss: 0.014390595876611768\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 155\n",
            "Train Loss: 0.0024587698391405864\n",
            "Validation Loss: 0.012730234260088765\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 156\n",
            "Train Loss: 0.0021851127821719274\n",
            "Validation Loss: 0.011165875961305574\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 157\n",
            "Train Loss: 0.0028294027180527336\n",
            "Validation Loss: 0.01563835975015536\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 158\n",
            "Train Loss: 0.0036609866929939016\n",
            "Validation Loss: 0.015395082284230739\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 159\n",
            "Train Loss: 0.0027955433813622223\n",
            "Validation Loss: 0.014473065533675254\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 160\n",
            "Train Loss: 0.0026788142957957463\n",
            "Validation Loss: 0.013838553055538796\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 161\n",
            "Train Loss: 0.0024694017646834255\n",
            "Validation Loss: 0.013368880324997008\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 162\n",
            "Train Loss: 0.0026303073449525983\n",
            "Validation Loss: 0.01565415174642112\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 163\n",
            "Train Loss: 0.002649103910662234\n",
            "Validation Loss: 0.013628132394514977\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 164\n",
            "Train Loss: 0.0024857512112066616\n",
            "Validation Loss: 0.013692389096831903\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 165\n",
            "Train Loss: 0.002843594516161829\n",
            "Validation Loss: 0.015358141377801076\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 166\n",
            "Train Loss: 0.002577055388246663\n",
            "Validation Loss: 0.013337267254246398\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 167\n",
            "Train Loss: 0.002497246091661509\n",
            "Validation Loss: 0.0134188987466041\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 168\n",
            "Train Loss: 0.002614028357202187\n",
            "Validation Loss: 0.013363958289264701\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 169\n",
            "Train Loss: 0.0032986203097971154\n",
            "Validation Loss: 0.015092035543639214\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 170\n",
            "Train Loss: 0.0026752235501771794\n",
            "Validation Loss: 0.013865982912248\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 171\n",
            "Train Loss: 0.002496562783489935\n",
            "Validation Loss: 0.014094433577265591\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 172\n",
            "Train Loss: 0.0026990908628795295\n",
            "Validation Loss: 0.01315695328055881\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 173\n",
            "Train Loss: 0.002444304721429944\n",
            "Validation Loss: 0.012878758480073884\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 174\n",
            "Train Loss: 0.002501753066317178\n",
            "Validation Loss: 0.015926828049123286\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 175\n",
            "Train Loss: 0.002631485458696261\n",
            "Validation Loss: 0.015656045438954606\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 176\n",
            "Train Loss: 0.0028054311337473337\n",
            "Validation Loss: 0.013049147262936458\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 177\n",
            "Train Loss: 0.002494807682232931\n",
            "Validation Loss: 0.013221517513738946\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 178\n",
            "Train Loss: 0.002418364705517888\n",
            "Validation Loss: 0.013280471203033812\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 179\n",
            "Train Loss: 0.0024953401181846855\n",
            "Validation Loss: 0.012829919359646738\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 180\n",
            "Train Loss: 0.002629697522497736\n",
            "Validation Loss: 0.015205219618510455\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 181\n",
            "Train Loss: 0.0030782468046527357\n",
            "Validation Loss: 0.021623099672724494\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 182\n",
            "Train Loss: 0.0058817757375072685\n",
            "Validation Loss: 0.014923412255593576\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 183\n",
            "Train Loss: 0.0027608354535186663\n",
            "Validation Loss: 0.013461464950814843\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 184\n",
            "Train Loss: 0.0025046756822848693\n",
            "Validation Loss: 0.014489785062614828\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 185\n",
            "Train Loss: 0.0026339717459632084\n",
            "Validation Loss: 0.014117305771214887\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 186\n",
            "Train Loss: 0.0025721459224587306\n",
            "Validation Loss: 0.014486057221656665\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 187\n",
            "Train Loss: 0.002719107199227437\n",
            "Validation Loss: 0.015141757349483668\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 188\n",
            "Train Loss: 0.0025780134493834338\n",
            "Validation Loss: 0.01433062560041435\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 189\n",
            "Train Loss: 0.0025259341776836665\n",
            "Validation Loss: 0.014162839748896658\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 190\n",
            "Train Loss: 0.0025320582021959126\n",
            "Validation Loss: 0.012611485529341736\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 191\n",
            "Train Loss: 0.002345710593071999\n",
            "Validation Loss: 0.012480126165319233\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 192\n",
            "Train Loss: 0.0024554802756756545\n",
            "Validation Loss: 0.014329429930076003\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 193\n",
            "Train Loss: 0.0025470283854519948\n",
            "Validation Loss: 0.014286218787310645\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 194\n",
            "Train Loss: 0.002491279448149726\n",
            "Validation Loss: 0.014154300483496626\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 195\n",
            "Train Loss: 0.0025312518721329978\n",
            "Validation Loss: 0.011835209073033183\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 196\n",
            "Train Loss: 0.002451987136155367\n",
            "Validation Loss: 0.012674135381821543\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 197\n",
            "Train Loss: 0.0024293420556932687\n",
            "Validation Loss: 0.015523391813039779\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 198\n",
            "Train Loss: 0.0034772624023025854\n",
            "Validation Loss: 0.01330393817042932\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 199\n",
            "Train Loss: 0.0024534359318204224\n",
            "Validation Loss: 0.012722612655488774\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train module\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = BCAgent(obs_space, action_space)\n",
        "loss_criterion = nn.MSELoss()\n",
        "# Create a learning rate scheduler\n",
        "step_size = 50\n",
        "gamma = 0.1\n",
        "# scheduler = \n",
        "optimizer =  optim.Adam(policy.parameters(), lr=1e-2)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "eval_epochs = 5\n",
        "\n",
        "train(policy, \n",
        "      train_epochs=200, \n",
        "      eval_epochs=5, \n",
        "      train_loader=train_loader, \n",
        "      test_loader=test_loader,\n",
        "      optimizer=optimizer,\n",
        "      loss_criterion=loss_criterion,\n",
        "      scheduler=scheduler,\n",
        "      trashold = 100\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "82745485",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save trained model\n",
        "\n",
        "torch.save(policy.state_dict, './checkpoints/'+policy.name.lower()+'new' + '.pt')\n",
        "\n",
        "\n",
        "\n",
        "#qui finisce "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efeb12bf",
      "metadata": {},
      "source": [
        "## Legacy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c7a5b24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c7a5b24",
        "outputId": "88c86e15-4dea-434a-97c2-d976be5ce2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "use_cuda:  False\n"
          ]
        }
      ],
      "source": [
        "###### Define student agent\n",
        "\n",
        "\n",
        "class StudentAgent:\n",
        "    def __init__(self, train_loader, test_loader, learning_rate, threshold):\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        n_inputs = train_loader.dataset.__getitem__(0)[0].shape[0] # dimension of observation space (of state = 196)\n",
        "        n_outputs = train_loader.dataset.__getitem__(0)[1].shape[0] # dimension of actions space (of outptu = 36)\n",
        "\n",
        "        #simple layer\n",
        "        self.policy = nn.Sequential(\n",
        "            # nn.BatchNorm1d(n_inputs),\n",
        "            nn.Linear(n_inputs, 16), \n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, n_outputs),\n",
        "            # nn.BatchNorm1d(n_outputs)\n",
        "            # nn.Softmax(dim=-1)\n",
        "            )\n",
        "\n",
        "        print(\"policy net: \", self.policy)\n",
        "\n",
        "        # self.loss_criterion = nn.HuberLoss() #nn.MSELoss()\n",
        "        self.loss_criterion = nn.MSELoss()\n",
        "\n",
        "        self.optimizer =  optim.Adam(self.policy.parameters(), lr=learning_rate)\n",
        "        self.num_eval_episodes = 5\n",
        "        self.accuracy_threshold = threshold\n",
        "\n",
        "    def print_gradients(self):\n",
        "        for name, param in self.policy.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if torch.isnan(param.grad).any(): \n",
        "                    return 1#break\n",
        "                # print(f\"Gradient of {name}: {param.grad}\")\n",
        "        return 0\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        self.policy.train()\n",
        "        self.policy.to(device)\n",
        "        \n",
        "        loss = 0\n",
        "        epoch_loss = 0\n",
        "        unused_val = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                obs = obs.float()\n",
        "\n",
        "                student_action = self.policy(obs)\n",
        "                expert_action = expert_action.float()\n",
        "\n",
        "                loss = self.loss_criterion(student_action, expert_action)\n",
        "                # loss.register_hook(lambda grad: print(grad))\n",
        "                loss.backward()\n",
        "                # print(\"Loss: {}\".format(loss.item()))\n",
        "                \n",
        "                \n",
        "                if not loss.item() == torch.inf: \n",
        "                    epoch_loss += loss.item()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                else:\n",
        "                    unused_val += 1\n",
        "                    # print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                    # print(f'obs -> {obs}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'expert_action -> {expert_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'student_action -> {student_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    return expert_action,student_action\n",
        "\n",
        "                res = self.print_gradients()\n",
        "                \n",
        "                # print(\"###############################################################################\\n\")\n",
        "\n",
        "                if torch.isnan(student_action).any(): \n",
        "                    print('e successo')\n",
        "                    break\n",
        "                if res == 1: \n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(student_action.shape)\n",
        "                    for i, ea in enumerate(expert_action):\n",
        "                        if not np.isfinite(ea).all():\n",
        "                            print(i+64)\n",
        "                            print(f'expert_action -> {ea}')\n",
        "\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'Max expert_action -> {expert_action.max()}')\n",
        "                    print(f'Min expert_action -> {expert_action.min()}')\n",
        "                    print(f'Max student_action -> {student_action.max()}')\n",
        "                    print(f'Min student_action -> {student_action.min()}')\n",
        "                    break\n",
        "                \n",
        "                # print(\"Student actions: {}\".format(student_action.shape))\n",
        "                # print(\"Expert actions: {}\".format(expert_action.shape))\n",
        "            \n",
        "            \n",
        "            # compute accuracy\n",
        "            train_acc = self.compute_accuracy(self.train_loader)\n",
        "            test_acc = self.compute_accuracy(self.test_loader)\n",
        "            # print(\"Epoch {}:\\ttrain accuracy: {}\\ttest accuracy: {}\".format(epoch, train_acc, test_acc))\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Train Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "            self.validation(test_loader, num_epochs=self.num_eval_episodes)\n",
        "            print(\"Unused Loss: {}\".format(unused_val))\n",
        "            epoch_loss = 0\n",
        "            unused_val = 0\n",
        "            # if train_acc >80. and test_acc>80.: return\n",
        "            print(\"###############################################################################\\n\")\n",
        "\n",
        "\n",
        "    def validation(self, loader, num_epochs):\n",
        "        self.policy.eval()\n",
        "        epoch_loss = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(loader):\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "                student_action = self.policy(obs)\n",
        "                loss = self.loss_criterion(student_action, expert_action)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        print(\"Validation Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, loader):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        self.policy.eval()\n",
        "        test_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loader:\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "                student_action = self.policy(obs)\n",
        "\n",
        "                total += student_action.size(0)\n",
        "\n",
        "                # print(\"Total: {}\".format(total))\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # print(f'expert_action -> {expert_action}')\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # print(f'student_action -> {student_action}')\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # similarity = math.isclose(student_action.any(), expert_action.any(), rel_tol=1e-5)\n",
        "\n",
        "                # difference = (expert_action - student_action).abs()\n",
        "                similarity= torch.abs(student_action - expert_action)\n",
        "                similarity = torch.sum(similarity,dim=1)/36\n",
        "                manual_mse = torch.mean(torch.square(student_action) - torch.square(expert_action),dim=0)\n",
        "\n",
        "                correct  += (similarity < self.accuracy_threshold).sum().item()\n",
        "                # print(f'similarity -> {similarity.shape}') # 64\n",
        "                # print(f'similarity -> {similarity.mean()}')\n",
        "                # print(f'similarity -> {similarity.shape}')\n",
        "\n",
        "                \n",
        "                # print(f'mse -> {manual_mse}')\n",
        "                # print(f'shape -> {manual_mse.shape}')\n",
        "\n",
        "\n",
        "                # print(f'correct -> {correct}')\n",
        "                # correct += int(similarity/total)\n",
        "                # correct += sum(student_action==expert_action).item()\n",
        "                \n",
        "\n",
        "        # print(f'correct -> {correct}')\n",
        "        accuracy = 100. * correct/(total)\n",
        "\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "86cbb1ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "policy net:  Sequential(\n",
            "  (0): Linear(in_features=196, out_features=16, bias=True)\n",
            "  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=16, out_features=36, bias=True)\n",
            ")\n",
            "Epoch 0\n",
            "Train Loss: 0.07781948585994541\n",
            "Validation Loss: 0.2355303904041648\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 1\n",
            "Train Loss: 0.044734375057742\n",
            "Validation Loss: 0.17950538225471974\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 0.034175390191376206\n",
            "Validation Loss: 0.1372361627779901\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 0.02608611384872347\n",
            "Validation Loss: 0.09255675294436515\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 0.016654929337091742\n",
            "Validation Loss: 0.06677638921886682\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 0.01241205916274339\n",
            "Validation Loss: 0.05499968620017171\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 0.010294352564960719\n",
            "Validation Loss: 0.049164203585824\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 0.009169357312493957\n",
            "Validation Loss: 0.0435595354065299\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 0.008364838290726767\n",
            "Validation Loss: 0.04070048514520749\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 0.007952852606540545\n",
            "Validation Loss: 0.03939801376312971\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 0.007545674868160859\n",
            "Validation Loss: 0.03847230819548713\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 0.007142638374352828\n",
            "Validation Loss: 0.03649844778701663\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 0.006942947676870972\n",
            "Validation Loss: 0.03497062069363892\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 0.006539730323420372\n",
            "Validation Loss: 0.03409587401896715\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 0.006375900324201211\n",
            "Validation Loss: 0.03409580633509904\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 0.006155590589623898\n",
            "Validation Loss: 0.031755756111815574\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 0.005846522649517283\n",
            "Validation Loss: 0.032243020631140096\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 0.005757020240998827\n",
            "Validation Loss: 0.03023309964686632\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 0.005615294149611145\n",
            "Validation Loss: 0.029317325633019208\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 0.005516500724916114\n",
            "Validation Loss: 0.028741663275286555\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 0.005410896084504202\n",
            "Validation Loss: 0.027778851709445006\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 0.005237182924756781\n",
            "Validation Loss: 0.02725683365948498\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 0.005219382469949779\n",
            "Validation Loss: 0.02662775181233883\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 0.005055637078721702\n",
            "Validation Loss: 0.026655846233479677\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 0.005056207068264484\n",
            "Validation Loss: 0.026319323596544562\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 0.004980890558799729\n",
            "Validation Loss: 0.024741466480772942\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 26\n",
            "Train Loss: 0.004834393972996623\n",
            "Validation Loss: 0.024761008191853763\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 27\n",
            "Train Loss: 0.005173409747658298\n",
            "Validation Loss: 0.02505181933287531\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 28\n",
            "Train Loss: 0.004722102221567184\n",
            "Validation Loss: 0.02341089183697477\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 29\n",
            "Train Loss: 0.0045821687669376845\n",
            "Validation Loss: 0.023078275616280734\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 30\n",
            "Train Loss: 0.0045842767832800745\n",
            "Validation Loss: 0.02405672618704557\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 31\n",
            "Train Loss: 0.004459935828926973\n",
            "Validation Loss: 0.023150472462875767\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 32\n",
            "Train Loss: 0.004436895224789623\n",
            "Validation Loss: 0.0220974093163386\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 33\n",
            "Train Loss: 0.0043501315684989095\n",
            "Validation Loss: 0.02183402262162417\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 34\n",
            "Train Loss: 0.004209465127205476\n",
            "Validation Loss: 0.02281108365976252\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 35\n",
            "Train Loss: 0.004165783345233649\n",
            "Validation Loss: 0.020603326784912498\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 36\n",
            "Train Loss: 0.004131536424392834\n",
            "Validation Loss: 0.02047410773811862\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 37\n",
            "Train Loss: 0.0040567181762889955\n",
            "Validation Loss: 0.020212749247439207\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 38\n",
            "Train Loss: 0.003974167975829914\n",
            "Validation Loss: 0.020363329860847445\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 39\n",
            "Train Loss: 0.003988942473079078\n",
            "Validation Loss: 0.02001597254537046\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 40\n",
            "Train Loss: 0.0038527313270606102\n",
            "Validation Loss: 0.0192568471445702\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 41\n",
            "Train Loss: 0.0039029610273428263\n",
            "Validation Loss: 0.018876236046198754\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 42\n",
            "Train Loss: 0.0038385004556039347\n",
            "Validation Loss: 0.02040017224440817\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 43\n",
            "Train Loss: 0.00376938330125995\n",
            "Validation Loss: 0.018958488795906305\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 44\n",
            "Train Loss: 0.0036595562868751586\n",
            "Validation Loss: 0.019390303008258343\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 45\n",
            "Train Loss: 0.0036242162267444656\n",
            "Validation Loss: 0.01882850511232391\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 46\n",
            "Train Loss: 0.0036028253415133805\n",
            "Validation Loss: 0.018817208961118013\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 47\n",
            "Train Loss: 0.0036230136582162233\n",
            "Validation Loss: 0.01855862419353798\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 48\n",
            "Train Loss: 0.0035477957676630467\n",
            "Validation Loss: 0.018360981307923793\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 49\n",
            "Train Loss: 0.0034917871555080636\n",
            "Validation Loss: 0.01908392648678273\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "student = StudentAgent(train_loader, test_loader, learning_rate=1e-3, threshold=1e-3)\n",
        "prova = student.train(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6ea67bf5",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'student' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_36079/1796818400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'student' is not defined"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "dest = '../checkpoints/'\n",
        "name = 'Behavioral-Cloning-Agent'\n",
        "name = 'Behavioral-Cloning-Agent_test2'\n",
        "if not exists(dest): \n",
        "  mkdir(dest)\n",
        "else: \n",
        "    if exists(dest+name.lower()+'.pt'):\n",
        "        remove(dest+name.lower()+'.pt')\n",
        "torch.save(student.policy.state_dict(), dest+name.lower()+'.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "policy net:  Sequential(\n",
            "  (0): Linear(in_features=196, out_features=16, bias=True)\n",
            "  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=16, out_features=36, bias=True)\n",
            ")\n",
            "torch.Size([1, 196])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(36,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#from torch tensor of [36,1] to numpy array [36]\n",
        "student = StudentAgent(train_loader, test_loader, learning_rate=1e-3, threshold=1e-3)\n",
        "obs = train_loader.dataset.__getitem__(0)[0].float().unsqueeze(0)\n",
        "print(obs.shape)\n",
        "student.policy.eval()  # Set the model to evaluation mode\n",
        "student.policy(obs).squeeze().detach().numpy().shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
