{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b09a0b12",
      "metadata": {
        "id": "b09a0b12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bitfra/miniconda3/envs/hum_rl/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from os.path import join, exists\n",
        "from os import mkdir, unlink, listdir, getpid, remove\n",
        "#from .autonotebook import tqdm as notebook_tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from statistics import mean\n",
        "import math\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce03945f",
      "metadata": {
        "id": "ce03945f"
      },
      "outputs": [],
      "source": [
        "##dataset class\n",
        "from torch.utils.data.dataset import Dataset, random_split\n",
        "\n",
        "class ExpertDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, expert_observations, expert_actions):\n",
        "        self.observations = torch.from_numpy(expert_observations)\n",
        "        self.actions = self.preprocess_data(torch.from_numpy(expert_actions))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # return (self.observations[index], self.actions[index])\n",
        "        normalized_observations = 2 * ((self.observations[idx] - self.observations.min()) / (self.observations.max() - self.observations.min())) - 1\n",
        "        # normalized_actions = 2 * ((self.actions[idx] - self.actions.min()) / (self.actions.max() - self.actions.min())) - 1\n",
        "        normalized_data = (normalized_observations, self.actions[idx])\n",
        "        return normalized_data\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations)\n",
        "    \n",
        "    def preprocess_data(self, data, clip_value=1e38):\n",
        "        # Clip values to a maximum and minimum range\n",
        "        data = torch.clamp(data, min=-clip_value, max=clip_value)\n",
        "        \n",
        "        # Convert to float\n",
        "        return data.float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "11af5407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11af5407",
        "outputId": "bc497a92-1701-4426-c1cd-4fb74f7545cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expert actions len: 8000\n",
            "Expert observations len: 8000\n",
            "Discarded data\n",
            "Discarded form np: 0\n",
            "Discarded form torch: 0\n",
            "Shapes:\n",
            "torch.Size([36])\n",
            "torch.Size([196])\n"
          ]
        }
      ],
      "source": [
        "expert_observations = np.load('./data/expert-observations.npy', allow_pickle=True)\n",
        "expert_actions = np.load('./data/expert-actions.npy', allow_pickle=True)\n",
        "\n",
        "count_discarded_numpy = 0\n",
        "count_discarded = 0\n",
        "\n",
        "\n",
        "new_exp_action = expert_actions\n",
        "\n",
        "list_of_index_to_drop = []\n",
        "for i, a in enumerate(expert_actions):\n",
        "  if (a > 1e2).any() or (a > 1e2).any():\n",
        "  # if not np.isfinite(a).all(): \n",
        "    list_of_index_to_drop.append(i)\n",
        "    print(i)\n",
        "    print(a)\n",
        "    count_discarded_numpy+=1\n",
        "    # break\n",
        "\n",
        "\n",
        "print(\"Expert actions len: {}\".format(len(expert_actions)))\n",
        "print(\"Expert observations len: {}\".format(len(expert_observations)))\n",
        "\n",
        "expert_dataset = ExpertDataSet(expert_observations, expert_actions)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(expert_dataset)):\n",
        "  a = expert_dataset.__getitem__(i)[1]\n",
        "  # print(a.max())\n",
        "  # print(a.min())\n",
        "  if (a > 1e2).any() or (a < -1e2).any() :\n",
        "  # if not torch.isfinite(a).any():\n",
        "    count_discarded += 1\n",
        "    print(a)\n",
        "\n",
        "\n",
        "print(\"Discarded data\")\n",
        "print(\"Discarded form np: {}\".format(count_discarded_numpy))\n",
        "print(\"Discarded form torch: {}\".format(count_discarded))\n",
        "\n",
        "#split in 80% training and 20%test\n",
        "batch_size = 64\n",
        "train_prop = 0.8\n",
        "train_size = int(train_prop * len(expert_dataset))\n",
        "test_size = len(expert_dataset) - train_size\n",
        "train_expert_dataset, test_expert_dataset = random_split(expert_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(  dataset=train_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(  dataset=test_expert_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(train_loader.dataset.__getitem__(0)[1].shape)\n",
        "print(train_loader.dataset.__getitem__(0)[0].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "94873ce1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Policy agent\n",
        "\n",
        "class BCAgent(nn.Module):\n",
        "\n",
        "  def __init__(self, obs_space, action_space) -> None:\n",
        "    self.name = 'Behavioral-Cloning-Agent'\n",
        "\n",
        "    super(BCAgent, self).__init__()\n",
        "\n",
        "    self.n_inputs = obs_space\n",
        "    self.n_outputs = action_space\n",
        "\n",
        "    # Policy Network\n",
        "    self.fc1 = nn.Linear(self.n_inputs,16)\n",
        "    self.bn1 = nn.BatchNorm1d(16)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(16, self.n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "  \n",
        "  def load_parameters(self, dir): \n",
        "    if exists(dir+self.name.lower()+'.pt'):\n",
        "        print(\"Loading model \"+self.name+\" state parameters\")\n",
        "        self.load_state_dict(torch.load(dir+self.name.lower()+'.pt', map_location=self.device))\n",
        "        return self\n",
        "    else:\n",
        "        print(\"Error no model \"+self.name.lower()+\" found!\")\n",
        "        exit(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "09e78876",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train functions\n",
        "\n",
        "def train(\n",
        "        policy,\n",
        "        train_epochs,\n",
        "        eval_epochs,\n",
        "        train_loader, \n",
        "        test_loader,\n",
        "        optimizer,\n",
        "        loss_criterion\n",
        "    ):\n",
        "\n",
        "    policy.train()\n",
        "    policy.to(device)\n",
        "    \n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "    unused_val = 0\n",
        "\n",
        "    for epoch in range(train_epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "            obs, expert_action = data.to(device), target.to(device)\n",
        "            obs = obs.float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            student_action = policy(obs)\n",
        "            expert_action = expert_action.float()\n",
        "\n",
        "            loss = loss_criterion(student_action, expert_action)\n",
        "            # loss.register_hook(lambda grad: print(grad))\n",
        "            loss.backward()\n",
        "            # print(\"Loss: {}\".format(loss.item()))\n",
        "            \n",
        "            \n",
        "            if not loss.item() == torch.inf: \n",
        "                epoch_loss += loss.item()\n",
        "                optimizer.step()\n",
        "\n",
        "            else:\n",
        "                unused_val += 1\n",
        "                # print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                # print(f'obs -> {obs}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                print(f'expert_action -> {expert_action}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                print(f'student_action -> {student_action}')\n",
        "                print(\"\\n______________________________________________________________________________\")\n",
        "                return expert_action,student_action\n",
        "\n",
        "            # res = print_gradients()\n",
        "            \n",
        "            # print(\"###############################################################################\\n\")\n",
        "\n",
        "            if torch.isnan(student_action).any(): \n",
        "                print('e successo')\n",
        "                break\n",
        "            # if res == 1: \n",
        "            #     print(\"\\n______________________________________________________________________________\")\n",
        "            #     print(student_action.shape)\n",
        "            #     for i, ea in enumerate(expert_action):\n",
        "            #         if not np.isfinite(ea).all():\n",
        "            #             print(i+64)\n",
        "            #             print(f'expert_action -> {ea}')\n",
        "\n",
        "            #     print(\"\\n______________________________________________________________________________\")\n",
        "            #     print(f'Max expert_action -> {expert_action.max()}')\n",
        "            #     print(f'Min expert_action -> {expert_action.min()}')\n",
        "            #     print(f'Max student_action -> {student_action.max()}')\n",
        "            #     print(f'Min student_action -> {student_action.min()}')\n",
        "            #     break\n",
        "            \n",
        "            # print(\"Student actions: {}\".format(student_action.shape))\n",
        "            # print(\"Expert actions: {}\".format(expert_action.shape))\n",
        "        \n",
        "        \n",
        "        # compute accuracy\n",
        "        print(\"Epoch {}\".format(epoch))\n",
        "        print(\"Train Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "        validation(test_loader,policy,loss_criterion,num_epochs=eval_epochs)\n",
        "        print(\"Unused Loss: {}\".format(unused_val))\n",
        "        epoch_loss = 0\n",
        "        unused_val = 0\n",
        "        print(\"###############################################################################\\n\")\n",
        "\n",
        "\n",
        "def validation(loader, policy,loss_criterion, num_epochs):\n",
        "    policy.eval()\n",
        "    epoch_loss = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_idx, (data, target) in enumerate(loader):\n",
        "            obs, expert_action = data.to(device), target.to(device)\n",
        "            obs = obs.float()\n",
        "            student_action = policy(obs)\n",
        "            loss = loss_criterion(student_action, expert_action)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    print(\"Validation Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "\n",
        "def print_gradients(self):\n",
        "    for name, param in self.policy.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            if torch.isnan(param.grad).any(): \n",
        "                return 1#break\n",
        "            # print(f\"Gradient of {name}: {param.grad}\")\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1d8a59c8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train Loss: 0.02913110813591629\n",
            "Validation Loss: 0.04770896966103464\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 1\n",
            "Train Loss: 0.012086623404175044\n",
            "Validation Loss: 0.042046367852017284\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 0.006125985241960734\n",
            "Validation Loss: 0.027066096207126977\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 0.005151718924753368\n",
            "Validation Loss: 0.02520924808923155\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 0.004393481366569176\n",
            "Validation Loss: 0.020114824217744173\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 0.0038958651752909646\n",
            "Validation Loss: 0.02247093102429062\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 0.003863672267762013\n",
            "Validation Loss: 0.019221893125213683\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 0.0035434430674649775\n",
            "Validation Loss: 0.017133133062161507\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 0.0033322893449803815\n",
            "Validation Loss: 0.016572352157672866\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 0.003847969306516461\n",
            "Validation Loss: 0.020127059516962618\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 0.003285561081720516\n",
            "Validation Loss: 0.016758640254847704\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 0.0030635573173640298\n",
            "Validation Loss: 0.015115099349059165\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 0.0028624187095556406\n",
            "Validation Loss: 0.015879063564352692\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 0.0030937416362576188\n",
            "Validation Loss: 0.014606942809186875\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 0.002880399644491263\n",
            "Validation Loss: 0.015826410297304392\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 0.0029200965783093124\n",
            "Validation Loss: 0.01523272370104678\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 0.002696227190317586\n",
            "Validation Loss: 0.01603758837794885\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 0.0027728090109303593\n",
            "Validation Loss: 0.013856175991822966\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 0.002654689472983591\n",
            "Validation Loss: 0.015012795463844668\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 0.0027406814263667913\n",
            "Validation Loss: 0.013659405484795571\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 0.0026381800160743298\n",
            "Validation Loss: 0.013140562993357889\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 0.002829331683606142\n",
            "Validation Loss: 0.016787664662115277\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 0.0026953746296931058\n",
            "Validation Loss: 0.015376102372538298\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 0.0024961519544012844\n",
            "Validation Loss: 0.013439811036223546\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 0.0025039085556636566\n",
            "Validation Loss: 0.015251289072912186\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 0.0024609441572101785\n",
            "Validation Loss: 0.013059796600136906\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 26\n",
            "Train Loss: 0.0026791749737458304\n",
            "Validation Loss: 0.013586554786888883\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 27\n",
            "Train Loss: 0.0024206855735974388\n",
            "Validation Loss: 0.012735499968985096\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 28\n",
            "Train Loss: 0.0024253235617652537\n",
            "Validation Loss: 0.012231269534677267\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 29\n",
            "Train Loss: 0.002378858375013806\n",
            "Validation Loss: 0.012225808694493025\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 30\n",
            "Train Loss: 0.0024970391910756006\n",
            "Validation Loss: 0.01260463752085343\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 31\n",
            "Train Loss: 0.002697776857530698\n",
            "Validation Loss: 0.013035735551966354\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 32\n",
            "Train Loss: 0.0026174814946716652\n",
            "Validation Loss: 0.012635864145122468\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 33\n",
            "Train Loss: 0.0024966438225237655\n",
            "Validation Loss: 0.013913996763876639\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 34\n",
            "Train Loss: 0.0026014805713202803\n",
            "Validation Loss: 0.012460932852700352\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 35\n",
            "Train Loss: 0.002287712178658694\n",
            "Validation Loss: 0.01215368527569808\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 36\n",
            "Train Loss: 0.002314653869379981\n",
            "Validation Loss: 0.012233544401824474\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 37\n",
            "Train Loss: 0.0024595827516168357\n",
            "Validation Loss: 0.012170059091877192\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 38\n",
            "Train Loss: 0.00253691827012517\n",
            "Validation Loss: 0.013131190345156939\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 39\n",
            "Train Loss: 0.0024193138553528113\n",
            "Validation Loss: 0.01269814751110971\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 40\n",
            "Train Loss: 0.002434992213966325\n",
            "Validation Loss: 0.01306546771666035\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 41\n",
            "Train Loss: 0.002521171462140046\n",
            "Validation Loss: 0.013192514823749661\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 42\n",
            "Train Loss: 0.002413291484117508\n",
            "Validation Loss: 0.014266138108214364\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 43\n",
            "Train Loss: 0.0023945303435903044\n",
            "Validation Loss: 0.011676049808738754\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 44\n",
            "Train Loss: 0.002316078578296583\n",
            "Validation Loss: 0.013337508058175445\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 45\n",
            "Train Loss: 0.002744702271884307\n",
            "Validation Loss: 0.013347673418466002\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 46\n",
            "Train Loss: 0.002624091191100888\n",
            "Validation Loss: 0.016744586220011116\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 47\n",
            "Train Loss: 0.0024390600630431435\n",
            "Validation Loss: 0.013852599234087392\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 48\n",
            "Train Loss: 0.002412950515281409\n",
            "Validation Loss: 0.015923350574448703\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 49\n",
            "Train Loss: 0.0023821071500424295\n",
            "Validation Loss: 0.011623579498191247\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 50\n",
            "Train Loss: 0.00230096585029969\n",
            "Validation Loss: 0.013770444479305297\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 51\n",
            "Train Loss: 0.0023192140477476643\n",
            "Validation Loss: 0.01330465768231079\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 52\n",
            "Train Loss: 0.0022756468478473835\n",
            "Validation Loss: 0.013935380324255675\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 53\n",
            "Train Loss: 0.0027048546622972934\n",
            "Validation Loss: 0.017607186015229672\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 54\n",
            "Train Loss: 0.0026282127969898283\n",
            "Validation Loss: 0.013428219807101413\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 55\n",
            "Train Loss: 0.002217029705789173\n",
            "Validation Loss: 0.013790059863822535\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 56\n",
            "Train Loss: 0.0023222948022885246\n",
            "Validation Loss: 0.014752134406007826\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 57\n",
            "Train Loss: 0.0023463009402621537\n",
            "Validation Loss: 0.01242396815563552\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 58\n",
            "Train Loss: 0.002143449290015269\n",
            "Validation Loss: 0.012941782951820642\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 59\n",
            "Train Loss: 0.0022285171822295524\n",
            "Validation Loss: 0.013357032670173795\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 60\n",
            "Train Loss: 0.002128627417841926\n",
            "Validation Loss: 0.012611165466951206\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 61\n",
            "Train Loss: 0.0024819835810922087\n",
            "Validation Loss: 0.01294635844998993\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 62\n",
            "Train Loss: 0.0023900063315522857\n",
            "Validation Loss: 0.011438638924155385\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 63\n",
            "Train Loss: 0.002150689086411148\n",
            "Validation Loss: 0.013449061517603696\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 64\n",
            "Train Loss: 0.0024079603046993723\n",
            "Validation Loss: 0.012751491291564889\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 65\n",
            "Train Loss: 0.0023362975526833906\n",
            "Validation Loss: 0.013428636039607226\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 66\n",
            "Train Loss: 0.0023280921374680473\n",
            "Validation Loss: 0.01254085459979251\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 67\n",
            "Train Loss: 0.0021694866314646787\n",
            "Validation Loss: 0.012223415954504163\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 68\n",
            "Train Loss: 0.002121201017362182\n",
            "Validation Loss: 0.011672059698030353\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 69\n",
            "Train Loss: 0.0024320073577109723\n",
            "Validation Loss: 0.012618957296945154\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 70\n",
            "Train Loss: 0.002379281999601517\n",
            "Validation Loss: 0.011463260115124285\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 71\n",
            "Train Loss: 0.002199053508229554\n",
            "Validation Loss: 0.011602947771316395\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 72\n",
            "Train Loss: 0.002096205814741552\n",
            "Validation Loss: 0.013546113665215671\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 73\n",
            "Train Loss: 0.002179549690627027\n",
            "Validation Loss: 0.013649880257435142\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 74\n",
            "Train Loss: 0.002131042121909559\n",
            "Validation Loss: 0.014083409211598336\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 75\n",
            "Train Loss: 0.0022298791070352307\n",
            "Validation Loss: 0.01122151486808434\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 76\n",
            "Train Loss: 0.0024263455130858346\n",
            "Validation Loss: 0.012726818522496615\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 77\n",
            "Train Loss: 0.002219513607560657\n",
            "Validation Loss: 0.013086395298596471\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 78\n",
            "Train Loss: 0.002537460938328877\n",
            "Validation Loss: 0.015301319600548596\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 79\n",
            "Train Loss: 0.00260706951841712\n",
            "Validation Loss: 0.013746397198410705\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 80\n",
            "Train Loss: 0.0022117334391805344\n",
            "Validation Loss: 0.012829697725828737\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 81\n",
            "Train Loss: 0.002098788819857873\n",
            "Validation Loss: 0.01150771786167752\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 82\n",
            "Train Loss: 0.0022130160848610105\n",
            "Validation Loss: 0.013832588576478884\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 83\n",
            "Train Loss: 0.002594965228345245\n",
            "Validation Loss: 0.012512685064575636\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 84\n",
            "Train Loss: 0.002142520692432299\n",
            "Validation Loss: 0.012172054196707905\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 85\n",
            "Train Loss: 0.002235518655506894\n",
            "Validation Loss: 0.012564075710251928\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 86\n",
            "Train Loss: 0.0024378613103181123\n",
            "Validation Loss: 0.014369691780302674\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 87\n",
            "Train Loss: 0.002339226689655334\n",
            "Validation Loss: 0.012266580741852521\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 88\n",
            "Train Loss: 0.002091334732831456\n",
            "Validation Loss: 0.0120436778513249\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 89\n",
            "Train Loss: 0.002121864050568547\n",
            "Validation Loss: 0.01119453923893161\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 90\n",
            "Train Loss: 0.0022300884954165666\n",
            "Validation Loss: 0.01122902552364394\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 91\n",
            "Train Loss: 0.001995298791152891\n",
            "Validation Loss: 0.011032212249701842\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 92\n",
            "Train Loss: 0.0020257402322022243\n",
            "Validation Loss: 0.012074994399445132\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 93\n",
            "Train Loss: 0.002108495879510883\n",
            "Validation Loss: 0.011532436441630125\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 94\n",
            "Train Loss: 0.0021191542863380165\n",
            "Validation Loss: 0.011663444717414677\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 95\n",
            "Train Loss: 0.002077051442465745\n",
            "Validation Loss: 0.012227318186778574\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 96\n",
            "Train Loss: 0.0020898256314103494\n",
            "Validation Loss: 0.011010929269250482\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 97\n",
            "Train Loss: 0.002113957908586599\n",
            "Validation Loss: 0.01169560561189428\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 98\n",
            "Train Loss: 0.0023088058334542437\n",
            "Validation Loss: 0.013128369617043063\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 99\n",
            "Train Loss: 0.002181626367964782\n",
            "Validation Loss: 0.01180707320687361\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train module\n",
        "obs_space = train_loader.dataset.__getitem__(0)[0].shape[0]\n",
        "action_space = train_loader.dataset.__getitem__(0)[1].shape[0]\n",
        "policy = BCAgent(obs_space, action_space)\n",
        "loss_criterion = nn.MSELoss()\n",
        "optimizer =  optim.Adam(policy.parameters(), lr=1e-2)\n",
        "eval_epochs = 5\n",
        "\n",
        "train(policy, \n",
        "      train_epochs=100, \n",
        "      eval_epochs=5, \n",
        "      train_loader=train_loader, \n",
        "      test_loader=test_loader,\n",
        "      optimizer=optimizer,\n",
        "      loss_criterion=loss_criterion\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "82745485",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save trained model\n",
        "\n",
        "torch.save(policy.state_dict, './checkpoints/'+policy.name.lower()+'.pt')\n",
        "\n",
        "\n",
        "\n",
        "#qui finisce "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efeb12bf",
      "metadata": {},
      "source": [
        "## Legacy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c7a5b24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c7a5b24",
        "outputId": "88c86e15-4dea-434a-97c2-d976be5ce2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "use_cuda:  False\n"
          ]
        }
      ],
      "source": [
        "###### Define student agent\n",
        "\n",
        "\n",
        "class StudentAgent:\n",
        "    def __init__(self, train_loader, test_loader, learning_rate, threshold):\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "\n",
        "        n_inputs = train_loader.dataset.__getitem__(0)[0].shape[0] # dimension of observation space (of state = 196)\n",
        "        n_outputs = train_loader.dataset.__getitem__(0)[1].shape[0] # dimension of actions space (of outptu = 36)\n",
        "\n",
        "        #simple layer\n",
        "        self.policy = nn.Sequential(\n",
        "            # nn.BatchNorm1d(n_inputs),\n",
        "            nn.Linear(n_inputs, 16), \n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, n_outputs),\n",
        "            # nn.BatchNorm1d(n_outputs)\n",
        "            # nn.Softmax(dim=-1)\n",
        "            )\n",
        "\n",
        "        print(\"policy net: \", self.policy)\n",
        "\n",
        "        # self.loss_criterion = nn.HuberLoss() #nn.MSELoss()\n",
        "        self.loss_criterion = nn.MSELoss()\n",
        "\n",
        "        self.optimizer =  optim.Adam(self.policy.parameters(), lr=learning_rate)\n",
        "        self.num_eval_episodes = 5\n",
        "        self.accuracy_threshold = threshold\n",
        "\n",
        "    def print_gradients(self):\n",
        "        for name, param in self.policy.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if torch.isnan(param.grad).any(): \n",
        "                    return 1#break\n",
        "                # print(f\"Gradient of {name}: {param.grad}\")\n",
        "        return 0\n",
        "\n",
        "    def train(self, num_epochs):\n",
        "        self.policy.train()\n",
        "        self.policy.to(device)\n",
        "        \n",
        "        loss = 0\n",
        "        epoch_loss = 0\n",
        "        unused_val = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                obs = obs.float()\n",
        "\n",
        "                student_action = self.policy(obs)\n",
        "                expert_action = expert_action.float()\n",
        "\n",
        "                loss = self.loss_criterion(student_action, expert_action)\n",
        "                # loss.register_hook(lambda grad: print(grad))\n",
        "                loss.backward()\n",
        "                # print(\"Loss: {}\".format(loss.item()))\n",
        "                \n",
        "                \n",
        "                if not loss.item() == torch.inf: \n",
        "                    epoch_loss += loss.item()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                else:\n",
        "                    unused_val += 1\n",
        "                    # print(\"### BATCH {} ###\".format(batch_idx))\n",
        "                    # print(f'obs -> {obs}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'expert_action -> {expert_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'student_action -> {student_action}')\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    return expert_action,student_action\n",
        "\n",
        "                res = self.print_gradients()\n",
        "                \n",
        "                # print(\"###############################################################################\\n\")\n",
        "\n",
        "                if torch.isnan(student_action).any(): \n",
        "                    print('e successo')\n",
        "                    break\n",
        "                if res == 1: \n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(student_action.shape)\n",
        "                    for i, ea in enumerate(expert_action):\n",
        "                        if not np.isfinite(ea).all():\n",
        "                            print(i+64)\n",
        "                            print(f'expert_action -> {ea}')\n",
        "\n",
        "                    print(\"\\n______________________________________________________________________________\")\n",
        "                    print(f'Max expert_action -> {expert_action.max()}')\n",
        "                    print(f'Min expert_action -> {expert_action.min()}')\n",
        "                    print(f'Max student_action -> {student_action.max()}')\n",
        "                    print(f'Min student_action -> {student_action.min()}')\n",
        "                    break\n",
        "                \n",
        "                # print(\"Student actions: {}\".format(student_action.shape))\n",
        "                # print(\"Expert actions: {}\".format(expert_action.shape))\n",
        "            \n",
        "            \n",
        "            # compute accuracy\n",
        "            train_acc = self.compute_accuracy(self.train_loader)\n",
        "            test_acc = self.compute_accuracy(self.test_loader)\n",
        "            # print(\"Epoch {}:\\ttrain accuracy: {}\\ttest accuracy: {}\".format(epoch, train_acc, test_acc))\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Train Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "            self.validation(test_loader, num_epochs=self.num_eval_episodes)\n",
        "            print(\"Unused Loss: {}\".format(unused_val))\n",
        "            epoch_loss = 0\n",
        "            unused_val = 0\n",
        "            # if train_acc >80. and test_acc>80.: return\n",
        "            print(\"###############################################################################\\n\")\n",
        "\n",
        "\n",
        "    def validation(self, loader, num_epochs):\n",
        "        self.policy.eval()\n",
        "        epoch_loss = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            for batch_idx, (data, target) in enumerate(loader):\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "                student_action = self.policy(obs)\n",
        "                loss = self.loss_criterion(student_action, expert_action)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "        print(\"Validation Loss: {}\".format(epoch_loss/(batch_idx+1)))\n",
        "\n",
        "\n",
        "\n",
        "    def compute_accuracy(self, loader):\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        self.policy.eval()\n",
        "        test_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loader:\n",
        "                obs, expert_action = data.to(device), target.to(device)\n",
        "                obs = obs.float()\n",
        "                student_action = self.policy(obs)\n",
        "\n",
        "                total += student_action.size(0)\n",
        "\n",
        "                # print(\"Total: {}\".format(total))\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # print(f'expert_action -> {expert_action}')\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # print(f'student_action -> {student_action}')\n",
        "                # print(\"\\n______________________________________________________________________________\")\n",
        "                # similarity = math.isclose(student_action.any(), expert_action.any(), rel_tol=1e-5)\n",
        "\n",
        "                # difference = (expert_action - student_action).abs()\n",
        "                similarity= torch.abs(student_action - expert_action)\n",
        "                similarity = torch.sum(similarity,dim=1)/36\n",
        "                manual_mse = torch.mean(torch.square(student_action) - torch.square(expert_action),dim=0)\n",
        "\n",
        "                correct  += (similarity < self.accuracy_threshold).sum().item()\n",
        "                # print(f'similarity -> {similarity.shape}') # 64\n",
        "                # print(f'similarity -> {similarity.mean()}')\n",
        "                # print(f'similarity -> {similarity.shape}')\n",
        "\n",
        "                \n",
        "                # print(f'mse -> {manual_mse}')\n",
        "                # print(f'shape -> {manual_mse.shape}')\n",
        "\n",
        "\n",
        "                # print(f'correct -> {correct}')\n",
        "                # correct += int(similarity/total)\n",
        "                # correct += sum(student_action==expert_action).item()\n",
        "                \n",
        "\n",
        "        # print(f'correct -> {correct}')\n",
        "        accuracy = 100. * correct/(total)\n",
        "\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "86cbb1ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "policy net:  Sequential(\n",
            "  (0): Linear(in_features=196, out_features=16, bias=True)\n",
            "  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=16, out_features=36, bias=True)\n",
            ")\n",
            "Epoch 0\n",
            "Train Loss: 0.07781948585994541\n",
            "Validation Loss: 0.2355303904041648\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 1\n",
            "Train Loss: 0.044734375057742\n",
            "Validation Loss: 0.17950538225471974\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 0.034175390191376206\n",
            "Validation Loss: 0.1372361627779901\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 0.02608611384872347\n",
            "Validation Loss: 0.09255675294436515\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 0.016654929337091742\n",
            "Validation Loss: 0.06677638921886682\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 0.01241205916274339\n",
            "Validation Loss: 0.05499968620017171\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 6\n",
            "Train Loss: 0.010294352564960719\n",
            "Validation Loss: 0.049164203585824\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 7\n",
            "Train Loss: 0.009169357312493957\n",
            "Validation Loss: 0.0435595354065299\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 8\n",
            "Train Loss: 0.008364838290726767\n",
            "Validation Loss: 0.04070048514520749\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 9\n",
            "Train Loss: 0.007952852606540545\n",
            "Validation Loss: 0.03939801376312971\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 10\n",
            "Train Loss: 0.007545674868160859\n",
            "Validation Loss: 0.03847230819548713\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 11\n",
            "Train Loss: 0.007142638374352828\n",
            "Validation Loss: 0.03649844778701663\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 12\n",
            "Train Loss: 0.006942947676870972\n",
            "Validation Loss: 0.03497062069363892\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 13\n",
            "Train Loss: 0.006539730323420372\n",
            "Validation Loss: 0.03409587401896715\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 14\n",
            "Train Loss: 0.006375900324201211\n",
            "Validation Loss: 0.03409580633509904\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 15\n",
            "Train Loss: 0.006155590589623898\n",
            "Validation Loss: 0.031755756111815574\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 16\n",
            "Train Loss: 0.005846522649517283\n",
            "Validation Loss: 0.032243020631140096\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 17\n",
            "Train Loss: 0.005757020240998827\n",
            "Validation Loss: 0.03023309964686632\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 18\n",
            "Train Loss: 0.005615294149611145\n",
            "Validation Loss: 0.029317325633019208\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 19\n",
            "Train Loss: 0.005516500724916114\n",
            "Validation Loss: 0.028741663275286555\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 20\n",
            "Train Loss: 0.005410896084504202\n",
            "Validation Loss: 0.027778851709445006\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 21\n",
            "Train Loss: 0.005237182924756781\n",
            "Validation Loss: 0.02725683365948498\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 22\n",
            "Train Loss: 0.005219382469949779\n",
            "Validation Loss: 0.02662775181233883\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 23\n",
            "Train Loss: 0.005055637078721702\n",
            "Validation Loss: 0.026655846233479677\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 24\n",
            "Train Loss: 0.005056207068264484\n",
            "Validation Loss: 0.026319323596544562\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 25\n",
            "Train Loss: 0.004980890558799729\n",
            "Validation Loss: 0.024741466480772942\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 26\n",
            "Train Loss: 0.004834393972996623\n",
            "Validation Loss: 0.024761008191853763\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 27\n",
            "Train Loss: 0.005173409747658298\n",
            "Validation Loss: 0.02505181933287531\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 28\n",
            "Train Loss: 0.004722102221567184\n",
            "Validation Loss: 0.02341089183697477\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 29\n",
            "Train Loss: 0.0045821687669376845\n",
            "Validation Loss: 0.023078275616280734\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 30\n",
            "Train Loss: 0.0045842767832800745\n",
            "Validation Loss: 0.02405672618704557\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 31\n",
            "Train Loss: 0.004459935828926973\n",
            "Validation Loss: 0.023150472462875767\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 32\n",
            "Train Loss: 0.004436895224789623\n",
            "Validation Loss: 0.0220974093163386\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 33\n",
            "Train Loss: 0.0043501315684989095\n",
            "Validation Loss: 0.02183402262162417\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 34\n",
            "Train Loss: 0.004209465127205476\n",
            "Validation Loss: 0.02281108365976252\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 35\n",
            "Train Loss: 0.004165783345233649\n",
            "Validation Loss: 0.020603326784912498\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 36\n",
            "Train Loss: 0.004131536424392834\n",
            "Validation Loss: 0.02047410773811862\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 37\n",
            "Train Loss: 0.0040567181762889955\n",
            "Validation Loss: 0.020212749247439207\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 38\n",
            "Train Loss: 0.003974167975829914\n",
            "Validation Loss: 0.020363329860847445\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 39\n",
            "Train Loss: 0.003988942473079078\n",
            "Validation Loss: 0.02001597254537046\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 40\n",
            "Train Loss: 0.0038527313270606102\n",
            "Validation Loss: 0.0192568471445702\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 41\n",
            "Train Loss: 0.0039029610273428263\n",
            "Validation Loss: 0.018876236046198754\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 42\n",
            "Train Loss: 0.0038385004556039347\n",
            "Validation Loss: 0.02040017224440817\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 43\n",
            "Train Loss: 0.00376938330125995\n",
            "Validation Loss: 0.018958488795906305\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 44\n",
            "Train Loss: 0.0036595562868751586\n",
            "Validation Loss: 0.019390303008258343\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 45\n",
            "Train Loss: 0.0036242162267444656\n",
            "Validation Loss: 0.01882850511232391\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 46\n",
            "Train Loss: 0.0036028253415133805\n",
            "Validation Loss: 0.018817208961118013\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 47\n",
            "Train Loss: 0.0036230136582162233\n",
            "Validation Loss: 0.01855862419353798\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 48\n",
            "Train Loss: 0.0035477957676630467\n",
            "Validation Loss: 0.018360981307923793\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n",
            "Epoch 49\n",
            "Train Loss: 0.0034917871555080636\n",
            "Validation Loss: 0.01908392648678273\n",
            "Unused Loss: 0\n",
            "###############################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "student = StudentAgent(train_loader, test_loader, learning_rate=1e-3, threshold=1e-3)\n",
        "prova = student.train(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6ea67bf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "dest = '../checkpoints/'\n",
        "name = 'Behavioral-Cloning-Agent'\n",
        "if not exists(dest): \n",
        "  mkdir(dest)\n",
        "else: \n",
        "    if exists(dest+name.lower()+'.pt'):\n",
        "        remove(dest+name.lower()+'.pt')\n",
        "torch.save(student.policy.state_dict(), dest+name.lower()+'.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "policy net:  Sequential(\n",
            "  (0): Linear(in_features=196, out_features=16, bias=True)\n",
            "  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=16, out_features=36, bias=True)\n",
            ")\n",
            "torch.Size([1, 196])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(36,)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#from torch tensor of [36,1] to numpy array [36]\n",
        "student = StudentAgent(train_loader, test_loader, learning_rate=1e-3, threshold=1e-3)\n",
        "obs = train_loader.dataset.__getitem__(0)[0].float().unsqueeze(0)\n",
        "print(obs.shape)\n",
        "student.policy.eval()  # Set the model to evaluation mode\n",
        "student.policy(obs).squeeze().detach().numpy().shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
